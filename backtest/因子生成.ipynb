{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yiwei/Desktop/git/Monterey/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "from datetime import date, datetime, timedelta, timezone\n",
    "import copy\n",
    "from pandas import IndexSlice as idx\n",
    "pd.set_option('display.max_columns', None)  # 当列太多时不换行\n",
    "from numpy import exp, nan\n",
    "import quantstats as qs\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # 忽略警告\n",
    "import pandas as pd\n",
    "from pandas import IndexSlice as idx\n",
    "\n",
    "import talib as ta\n",
    "# 计算natr\n",
    "def natr(df, n):\n",
    "    high = np.array([float(x) for x in df['high']])\n",
    "    low = np.array([float(x) for x in df['low']])\n",
    "    close = np.array([float(x) for x in df['close']])\n",
    "    df['natr'] = ta.NATR(high, low, close, timeperiod=n)\n",
    "    return df['natr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下为完整的可转债因子分类与计算顺序整理：\n",
    "\n",
    "# 一、基本价格与波动类因子（转债本身）\n",
    "\n",
    "# high, low, close, vol 基础字段\n",
    "\n",
    "# ma_20, momentum_20, volatility_20\n",
    "\n",
    "# max_value, max_value_position\n",
    "\n",
    "# zhengfu, zhengfu_cha\n",
    "\n",
    "# natr_14, natr_[1,3,5,10,20]\n",
    "\n",
    "# aft_high_cur_close\n",
    "\n",
    "# 二、OBV量能指标（转债）\n",
    "\n",
    "# obv, obv_5, obv_10, obv_ratio_5_10\n",
    "\n",
    "# 三、换手与市值类因子\n",
    "\n",
    "# turnover_pct\n",
    "\n",
    "# cap_float_share_rate\n",
    "\n",
    "# turnover_[5,10,20,60]_avg\n",
    "\n",
    "# rolling_[1,5,20,50]_avg\n",
    "\n",
    "# rolling_1_to_5_avg, rolling_5_to_20_avg, rolling_20_to_50_avg\n",
    "\n",
    "# 四、区间收益率（转债与股票）\n",
    "\n",
    "# pct_chg_[5,20]\n",
    "\n",
    "# pct_chg_stk_[5,20]\n",
    "\n",
    "# 五、成交量均值比因子（转债）\n",
    "\n",
    "# vol_[3,5,10,20,30,60]_avg\n",
    "\n",
    "# vol_[N]to[M]\n",
    "\n",
    "# 六、波动率与振幅（转债与股票）\n",
    "\n",
    "# bodong_[5,10,20,60], bodong_[5,10,20,60]_bd, bodong_20_to_bodong_60\n",
    "\n",
    "# zhengfu_[1,5,10,20,60], zhengfu_[1,5,10,20,60]_bodong\n",
    "\n",
    "# 七、跳空与缺口类因子（转债）\n",
    "\n",
    "# high_jump, low_gap, open_jump, gap_body_ratio\n",
    "\n",
    "# high_jump_count_[20,100,250]\n",
    "\n",
    "# low_gap_count_[20,100,250]\n",
    "\n",
    "# high_jump_count_[20,100,250]pct, low_gap_count[20,100,250]_pct\n",
    "\n",
    "# 八、K线结构因子（转债）\n",
    "\n",
    "# close_to_high_ratio, close_to_low_ratio\n",
    "\n",
    "# body_position, upper_shadow_ratio, lower_shadow_ratio\n",
    "\n",
    "# 九、趋势反转类Alpha因子（转债与股票）\n",
    "\n",
    "# alpha6, alpha6_stk\n",
    "\n",
    "# alpha12, alpha12_stk\n",
    "\n",
    "# alpha83, alpha83_stk\n",
    "\n",
    "# alpha18, alpha18_stk\n",
    "\n",
    "# alpha36, alpha36_stk\n",
    "\n",
    "# alpha89, alpha89_stk\n",
    "\n",
    "# alpha65, alpha65_stk\n",
    "\n",
    "# alpha76, alpha76_stk\n",
    "\n",
    "# alpha92, alpha92_stk\n",
    "\n",
    "# alpha99, alpha99_stk\n",
    "\n",
    "# 十、股票与转债联动因子\n",
    "\n",
    "# stk_up_bond_flat, stk_down_bond_weak, bond_hold_stk_rebound\n",
    "\n",
    "# stk_chg_[3,5], bond_chg_[3,5]\n",
    "\n",
    "# stk_up_bond_flat_[3,5]\n",
    "\n",
    "# stk_down_then_up, bond_rebound, bond_follow_stk_rebound\n",
    "\n",
    "# 十一、横纵向背离因子（股票与转债）\n",
    "\n",
    "# dev_bond_vs_stk_[3,5,10]\n",
    "\n",
    "# dev_bond_short[3]_long[20], dev_bond_short[5]_long[30]\n",
    "\n",
    "# dev_stk_short[3]_long[20], dev_stk_short[5]_long[30]\n",
    "\n",
    "# cb_vs_stk_ret_rank_diff_[3,5,10]\n",
    "\n",
    "# 十二、风险与回撤相关因子（转债）\n",
    "\n",
    "# cb_dev_from_low_5\n",
    "\n",
    "# cb_close_std_5\n",
    "\n",
    "# cb_drawdown_5\n",
    "\n",
    "# cb_dd_prob_estimate\n",
    "\n",
    "# 十三、震荡收敛类因子（转债）\n",
    "\n",
    "# atr_5, atr_10, atr_decay_5_10\n",
    "\n",
    "# close_std_5, close_std_10, vol_shrink_ratio\n",
    "\n",
    "# body_pct_mean_5\n",
    "\n",
    "# shadow_mean_5\n",
    "\n",
    "# small_body_shadow_ratio, doji_ratio_5\n",
    "\n",
    "# zhengfu_decay_5_20, range_ratio_5_20\n",
    "\n",
    "# 十四、脉冲与动能因子（转债）\n",
    "\n",
    "# high_jump_[15,20,30,40,50,60]\n",
    "\n",
    "# open_gap_mean_[5,10], open_gap_max_[5,10]\n",
    "\n",
    "# jump_atr_[3,5,10]\n",
    "\n",
    "# zscore_pctchg_20\n",
    "\n",
    "# vol_spike_ratio\n",
    "\n",
    "# vol_std_decay\n",
    "\n",
    "# score_high_jump_[15,20,30,40,50,60]_20\n",
    "\n",
    "# range_jump_potential\n",
    "\n",
    "# gap_and_go_flag\n",
    "\n",
    "# 十五、跌不动因子（转债）\n",
    "\n",
    "# down_freq_[5,10]\n",
    "\n",
    "# down_amp_[5,10]\n",
    "\n",
    "# no_fall_score_[5,10]\n",
    "\n",
    "# 十六、K线结构连续性\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(filepath):\n",
    "    df = pd.read_parquet(filepath)\n",
    "    df['high'] = df['high'].astype(float)\n",
    "    df['low'] = df['low'].astype(float)\n",
    "    df['close'] = df['close'].astype(float)\n",
    "    df['vol'] = df['vol'].astype(float)\n",
    "\n",
    "    # 常用因子\n",
    "    df['natr_14'] = ta.NATR(df['high'], df['low'], df['close'], timeperiod=14)\n",
    "    df['ma_20'] = ta.SMA(df['close'], timeperiod=20)\n",
    "    df['momentum_20'] = df['close'] / df['close'].shift(20)\n",
    "    df['volatility_20'] = df['close'].rolling(20).std()\n",
    "    df['max_value'] = df.groupby('code')['close'].cummax().shift(1)\n",
    "    df['max_value_position'] = df['close'] / df['max_value']\n",
    "    df['zhengfu'] = (df['high'] - df['low']) / df['close']\n",
    "    df['zhengfu_cha'] = (df['high'] - df['close']) / (df['open'] - df['close']).abs()\n",
    "\n",
    "    # OBV（On Balance vol）及其衍生指标\n",
    "    df['obv'] = df.groupby('code').apply(lambda x: ta.OBV(x['close'], x['vol'])).reset_index(level=0, drop=True)\n",
    "    df['obv_5'] = df.groupby('code')['obv'].rolling(5).mean().reset_index(level=0, drop=True)\n",
    "    df['obv_10'] = df.groupby('code')['obv'].rolling(10).mean().reset_index(level=0, drop=True)\n",
    "    df['obv_ratio_5_10'] = df['obv_5'] / df['obv_10']\n",
    "\n",
    "    # 多周期NATR\n",
    "    for n in [1, 3, 5, 10, 20]:\n",
    "        df[f'natr_{n}'] = df.groupby('code').apply(natr, n=n).reset_index(level=0, drop=True)\n",
    "\n",
    "    # 次日止盈特征\n",
    "    df['aft_high1'] = df.groupby('code')['high'].shift(-1)\n",
    "    df['aft_high_cur_close'] = (df['aft_high1'] - df['close']) / df['close']\n",
    "\n",
    "    # 换手率百分位、流通市值\n",
    "    df['turnover_pct'] = df.groupby('trade_date')['turnover'].rank(pct=True)\n",
    "    df['cap_float_share_rate'] = df['remain_cap'] * 10000 / (df['float_share'] * df['close_stk'])\n",
    "\n",
    "    # 区间收益率\n",
    "    for win in [5, 20]:\n",
    "        df['tmp'] = df['pct_chg'] + 1\n",
    "        df[f'pct_chg_{win}'] = df.groupby('code')['tmp'].rolling(win, min_periods=1).apply(np.prod, raw=True).reset_index(level=0, drop=True) - 1\n",
    "        del df['tmp']\n",
    "        df['tmp2'] = df['pct_chg_stk'] + 1\n",
    "        df[f'pct_chg_stk_{win}'] = df.groupby('code')['tmp2'].rolling(win, min_periods=1).apply(np.prod, raw=True).reset_index(level=0, drop=True) - 1\n",
    "        del df['tmp2']\n",
    "\n",
    "    # 均值换手率\n",
    "    for win in [5, 10, 20, 60]:\n",
    "        df[f'turnover_{win}_avg'] = df.groupby('code')['turnover'].rolling(window=win).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "    # 分位换手率\n",
    "    for win in [1, 5, 20, 50]:\n",
    "        df[f'rolling_{win}_avg'] = df.groupby('code')['turnover_pct'].rolling(window=win).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "    df['rolling_1_to_5_avg'] = df['rolling_1_avg'] / df['rolling_5_avg']\n",
    "    df['rolling_5_to_20_avg'] = df['rolling_5_avg'] / df['rolling_20_avg']\n",
    "    df['rolling_20_to_50_avg'] = df['rolling_20_avg'] / df['rolling_50_avg']\n",
    "\n",
    "    # 自动生成多组 N:M 量能比\n",
    "    vol_windows = [3, 5, 10, 20, 30, 60]\n",
    "    for n in vol_windows:\n",
    "        df[f'vol_{n}_avg'] = df.groupby('code')['vol'].rolling(n).mean().reset_index(level=0, drop=True)\n",
    "    for n in vol_windows:\n",
    "        for m in vol_windows:\n",
    "            if n < m:\n",
    "                df[f'vol_{n}_to_{m}'] = df[f'vol_{n}_avg'] / df[f'vol_{m}_avg']\n",
    "\n",
    "    # 波动率\n",
    "    for win in [5, 10, 20, 60]:\n",
    "        df[f'bodong_{win}'] = df.groupby('code')['pct_chg_stk'].rolling(win).std().reset_index(level=0, drop=True) * (win ** 0.5)\n",
    "        df[f'bodong_{win}_bd'] = df.groupby('code')['pct_chg'].rolling(win).std().reset_index(level=0, drop=True) * (win ** 0.5)\n",
    "\n",
    "    df['bodong_20_to_bodong_60'] = df['bodong_20'] / df['bodong_60']\n",
    "\n",
    "    # 振幅波动\n",
    "    for win in [1, 5, 10, 20, 60]:\n",
    "        df[f'zhengfu_{win}'] = df.groupby('code')['zhengfu'].rolling(win).std().reset_index(level=0, drop=True)\n",
    "        df[f'zhengfu_{win}_bodong'] = df[f'zhengfu_{win}'] * (win ** 0.5)\n",
    "\n",
    "    # # 跳空上涨/暴跌统计\n",
    "    # df['high_jump'] = (df['high'] / df['pre_close'] - 1) > 0.025\n",
    "    # df['close_drop'] = (df['close'] / df['pre_close'] - 1) < -0.02\n",
    "    # for win in [100, 250]:\n",
    "    #     df[f'high_jump_count_{win}'] = df.groupby('code')['high_jump'].rolling(window=win, min_periods=1).sum().reset_index(0, drop=True)\n",
    "    #     df[f'close_drop_count_{win}'] = df.groupby('code')['close_drop'].rolling(window=win, min_periods=1).sum().reset_index(0, drop=True)\n",
    "    #     df[f'high_jump_count_{win}_pct'] = df.groupby('trade_date')[f'high_jump_count_{win}'].rank(pct=True)\n",
    "    #     df.loc[df[f'high_jump_count_{win}_pct'] < 0.1, 'filter'] = True\n",
    "\n",
    "#     # =========================\n",
    "# # 原有代码中的指标计算（保留）\n",
    "# # =========================\n",
    "# # ... 你的原有指标计算逻辑保留不变 ...\n",
    "\n",
    "# # =========================\n",
    "# # 增强跳空与K线结构指标（新增）\n",
    "# # =========================\n",
    "#     df['high_jump'] = (df['high'] / df['pre_close'] - 1) > 0.025\n",
    "#     df['low_gap'] = (df['low'] / df['pre_close'] - 1) < -0.025\n",
    "#     df['open_jump'] = (df['open'] / df['pre_close'] - 1).abs()\n",
    "#     df['gap_body_ratio'] = (df['open'] - df['pre_close']) / (df['close'] - df['open']).replace(0, np.nan)\n",
    "\n",
    "#     for win in [20, 100, 250]:\n",
    "#         df[f'high_jump_count_{win}'] = df.groupby('code')['high_jump'].rolling(window=win, min_periods=1).sum().reset_index(0, drop=True)\n",
    "#         df[f'low_gap_count_{win}'] = df.groupby('code')['low_gap'].rolling(window=win, min_periods=1).sum().reset_index(0, drop=True)\n",
    "#         df[f'high_jump_count_{win}_pct'] = df.groupby('trade_date')[f'high_jump_count_{win}'].rank(pct=True)\n",
    "#         df[f'low_gap_count_{win}_pct'] = df.groupby('trade_date')[f'low_gap_count_{win}'].rank(pct=True)\n",
    "#         df.loc[df[f'high_jump_count_{win}_pct'] < 0.1, 'filter'] = True\n",
    "\n",
    "#     # 收盘价与高低点关系\n",
    "#     df['close_to_high_ratio'] = (df['close'] - df['low']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "#     df['close_to_low_ratio'] = (df['high'] - df['close']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "#     df['body_position'] = (df['close'] - df['open']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "#     df['upper_shadow_ratio'] = (df['high'] - df[['close', 'open']].max(axis=1)) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "#     df['lower_shadow_ratio'] = (df[['close', 'open']].min(axis=1) - df['low']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "\n",
    "# # =========================\n",
    "# # 示例策略（攻击型形态选股配置）\n",
    "# # =========================\n",
    "# # 攻击形态特征：\n",
    "# # - 高跳空概率 + 收盘接近最高\n",
    "# # - K线阳线、实体大、上影线短\n",
    "# # 可作为打分或过滤条件：\n",
    "# # config = {\n",
    "# #     'score_factors': {\n",
    "# #         'high_jump_count_20': 'desc',\n",
    "# #         'close_to_high_ratio': 'desc',\n",
    "# #         'upper_shadow_ratio': 'asc',\n",
    "# #         'body_position': 'desc'\n",
    "# #     }\n",
    "# # }\n",
    "\n",
    "#     # =========================\n",
    "# # Alpha101 & 联动因子模块（扩展+注释）\n",
    "# # =========================\n",
    "#     # Alpha6: -corr(rank(delta(close, 10)), rank(vol), 10)\n",
    "#     df['delta_close_10'] = df.groupby('code')['close'].diff(10)\n",
    "#     df['rank_delta_close_10'] = df.groupby('trade_date')['delta_close_10'].rank()\n",
    "#     df['rank_vol'] = df.groupby('trade_date')['vol'].rank()\n",
    "#     df['alpha6'] = df.groupby('code').apply(lambda x: x['rank_delta_close_10'].rolling(10).corr(x['rank_vol'])).reset_index(level=0, drop=True) * -1\n",
    "\n",
    "#     # Alpha12: sign(delta(vol, 1)) * -1 * delta(close, 1)\n",
    "#     df['delta_vol_1'] = df.groupby('code')['vol'].diff(1)\n",
    "#     df['delta_close_1'] = df.groupby('code')['close'].diff(1)\n",
    "#     df['alpha12'] = np.sign(df['delta_vol_1']) * -1 * df['delta_close_1']\n",
    "\n",
    "#     # Alpha83: rank(ts_argmax(close, 30)) → 30日内收盘最高价的位置\n",
    "#     df['alpha83'] = df.groupby('code')['close'].rolling(30).apply(lambda x: 29 - np.argmax(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "\n",
    "#     # 联动因子：股票涨、可转债没涨\n",
    "#     df['stk_up_bond_flat'] = ((df['pct_chg_stk'] > 0.03) & (df['pct_chg'] < 0.01)).astype(int)\n",
    "#     df['stk_down_bond_weak'] = ((df['pct_chg_stk'] < -0.03) & (df['pct_chg'] < df['pct_chg_stk'])).astype(int)\n",
    "#     df['bond_hold_stk_rebound'] = ((df['pct_chg_stk'].shift(1) < -0.03) & (df['pct_chg_stk'] > 0.01) & (df['pct_chg'] > 0.005)).astype(int)\n",
    "\n",
    "#     # 保存后返回\n",
    "#     # Alpha6: 趋势与成交量相关性，反转信号，值越小可能越强势（需做滑动相关）\n",
    "#     # Alpha6_stk: 正股版本\n",
    "#     df['delta_close_10_stk'] = df.groupby('code')['close_stk'].diff(10)\n",
    "#     df['rank_delta_close_10_stk'] = df.groupby('trade_date')['delta_close_10_stk'].rank()\n",
    "#     df['rank_vol_stk'] = df.groupby('trade_date')['vol_stk'].rank()\n",
    "#     df['alpha6_stk'] = df.groupby('code').apply(lambda x: x['rank_delta_close_10_stk'].rolling(10).corr(x['rank_vol_stk'])).reset_index(level=0, drop=True) * -1\n",
    "\n",
    "#     # Alpha12: 成交量变动的反向动量信号\n",
    "#     df['delta_vol_1_stk'] = df.groupby('code')['vol_stk'].diff(1)\n",
    "#     df['delta_close_1_stk'] = df.groupby('code')['close_stk'].diff(1)\n",
    "#     df['alpha12_stk'] = np.sign(df['delta_vol_1_stk']) * -1 * df['delta_close_1_stk']\n",
    "\n",
    "#     # Alpha83: 近30日高点出现时间，数值越小越强\n",
    "#     df['alpha83_stk'] = df.groupby('code')['close_stk'].rolling(30).apply(lambda x: 29 - np.argmax(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "\n",
    "#     # 联动因子增强：跨日多周期版本\n",
    "#     df['stk_chg_3'] = df.groupby('code')['pct_chg_stk'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "#     df['bond_chg_3'] = df.groupby('code')['pct_chg'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "#     df['stk_chg_5'] = df.groupby('code')['pct_chg_stk'].rolling(5).mean().reset_index(level=0, drop=True)\n",
    "#     df['bond_chg_5'] = df.groupby('code')['pct_chg'].rolling(5).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "#     # 滞涨因子：股票涨，转债不涨（补涨潜力）\n",
    "#     df['stk_up_bond_flat_3'] = ((df['stk_chg_3'] > 0.03) & (df['bond_chg_3'] < 0.01)).astype(int)\n",
    "#     df['stk_up_bond_flat_5'] = ((df['stk_chg_5'] > 0.05) & (df['bond_chg_5'] < 0.01)).astype(int)\n",
    "\n",
    "#     # 联动反转：股票大跌后反弹，转债跟涨（弹性机会）\n",
    "#     df['stk_down_then_up'] = ((df['pct_chg_stk'].shift(2) < -0.03) & (df['pct_chg_stk'] > 0.02)).astype(int)\n",
    "#     df['bond_rebound'] = (df['pct_chg'] > 0.01).astype(int)\n",
    "#     df['bond_follow_stk_rebound'] = ((df['stk_down_then_up'] == 1) & (df['bond_rebound'] == 1)).astype(int)\n",
    "\n",
    "    # =========================\n",
    "# Alpha101 & 联动因子模块（大幅扩展 + 注释 + 股票/转债联动）\n",
    "# =========================\n",
    "    # Alpha6: -corr(rank(delta(close, 10)), rank(vol), 10)\n",
    "    df['delta_close_10'] = df.groupby('code')['close'].diff(10)\n",
    "    df['rank_delta_close_10'] = df.groupby('trade_date')['delta_close_10'].rank()\n",
    "    df['rank_vol'] = df.groupby('trade_date')['vol'].rank()\n",
    "    df['alpha6'] = df.groupby('code').apply(lambda x: x['rank_delta_close_10'].rolling(10).corr(x['rank_vol'])).reset_index(level=0, drop=True) * -1\n",
    "\n",
    "    # Alpha12: sign(delta(vol, 1)) * -1 * delta(close, 1)\n",
    "    df['delta_vol_1'] = df.groupby('code')['vol'].diff(1)\n",
    "    df['delta_close_1'] = df.groupby('code')['close'].diff(1)\n",
    "    df['alpha12'] = np.sign(df['delta_vol_1']) * -1 * df['delta_close_1']\n",
    "\n",
    "    # Alpha83: rank(ts_argmax(close, 30)) → 30日内收盘最高价的位置\n",
    "    df['alpha83'] = df.groupby('code')['close'].rolling(30).apply(lambda x: 29 - np.argmax(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "\n",
    "    # 联动因子：股票涨、可转债没涨\n",
    "    df['stk_up_bond_flat'] = ((df['pct_chg_stk'] > 0.03) & (df['pct_chg'] < 0.01)).astype(int)\n",
    "    df['stk_down_bond_weak'] = ((df['pct_chg_stk'] < -0.03) & (df['pct_chg'] < df['pct_chg_stk'])).astype(int)\n",
    "    df['bond_hold_stk_rebound'] = ((df['pct_chg_stk'].shift(1) < -0.03) & (df['pct_chg_stk'] > 0.01) & (df['pct_chg'] > 0.005)).astype(int)\n",
    "\n",
    "    # 保存后返回\n",
    "    # Alpha6: 趋势与成交量相关性，反转信号，值越小可能越强势（需做滑动相关）\n",
    "    # Alpha6_stk: 正股版本\n",
    "    df['delta_close_10_stk'] = df.groupby('code')['close_stk'].diff(10)\n",
    "    df['rank_delta_close_10_stk'] = df.groupby('trade_date')['delta_close_10_stk'].rank()\n",
    "    df['rank_vol_stk'] = df.groupby('trade_date')['vol_stk'].rank()\n",
    "    df['alpha6_stk'] = df.groupby('code').apply(lambda x: x['rank_delta_close_10_stk'].rolling(10).corr(x['rank_vol_stk'])).reset_index(level=0, drop=True) * -1\n",
    "\n",
    "    # Alpha12: 成交量变动的反向动量信号\n",
    "    df['delta_vol_1_stk'] = df.groupby('code')['vol_stk'].diff(1)\n",
    "    df['delta_close_1_stk'] = df.groupby('code')['close_stk'].diff(1)\n",
    "    df['alpha12_stk'] = np.sign(df['delta_vol_1_stk']) * -1 * df['delta_close_1_stk']\n",
    "\n",
    "    # Alpha83: 近30日高点出现时间，数值越小越强\n",
    "    df['alpha83_stk'] = df.groupby('code')['close_stk'].rolling(30).apply(lambda x: 29 - np.argmax(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "\n",
    "    # 联动因子增强：跨日多周期版本（横向/纵向联动背离分析）\n",
    "    # 股票 & 转债收益横向对比（市场滞涨、异动识别）\n",
    "    for win in [3, 5, 10]:\n",
    "        df[f'stk_ret_{win}'] = df.groupby('code')['pct_chg_stk'].rolling(win).mean().reset_index(level=0, drop=True)\n",
    "        df[f'bond_ret_{win}'] = df.groupby('code')['pct_chg'].rolling(win).mean().reset_index(level=0, drop=True)\n",
    "        df[f'dev_bond_vs_stk_{win}'] = df[f'bond_ret_{win}'] - df[f'stk_ret_{win}']  # 横向背离值\n",
    "\n",
    "    # 转债自身历史偏离（纵向）：近期表现 vs 长期均值\n",
    "    for win_short, win_long in [(3, 20), (5, 30)]:\n",
    "        short = df.groupby('code')['pct_chg'].rolling(win_short).mean().reset_index(level=0, drop=True)\n",
    "        long = df.groupby('code')['pct_chg'].rolling(win_long).mean().reset_index(level=0, drop=True)\n",
    "        df[f'dev_bond_short{win_short}_long{win_long}'] = short - long\n",
    "\n",
    "    # 正股自身历史偏离（纵向）：最近几天表现 vs 自身长期均值\n",
    "    for win_short, win_long in [(3, 20), (5, 30)]:\n",
    "        short = df.groupby('code')['pct_chg_stk'].rolling(win_short).mean().reset_index(level=0, drop=True)\n",
    "        long = df.groupby('code')['pct_chg_stk'].rolling(win_long).mean().reset_index(level=0, drop=True)\n",
    "        df[f'dev_stk_short{win_short}_long{win_long}'] = short - long\n",
    "    df['stk_chg_3'] = df.groupby('code')['pct_chg_stk'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "    df['bond_chg_3'] = df.groupby('code')['pct_chg'].rolling(3).mean().reset_index(level=0, drop=True)\n",
    "    df['stk_chg_5'] = df.groupby('code')['pct_chg_stk'].rolling(5).mean().reset_index(level=0, drop=True)\n",
    "    df['bond_chg_5'] = df.groupby('code')['pct_chg'].rolling(5).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "    # 滞涨因子：股票涨，转债不涨（补涨潜力）\n",
    "    df['stk_up_bond_flat_3'] = ((df['stk_chg_3'] > 0.03) & (df['bond_chg_3'] < 0.01)).astype(int)\n",
    "    df['stk_up_bond_flat_5'] = ((df['stk_chg_5'] > 0.05) & (df['bond_chg_5'] < 0.01)).astype(int)\n",
    "\n",
    "    # 联动反转：股票大跌后反弹，转债跟涨（弹性机会）\n",
    "    df['stk_down_then_up'] = ((df['pct_chg_stk'].shift(2) < -0.03) & (df['pct_chg_stk'] > 0.02)).astype(int)\n",
    "    df['bond_rebound'] = (df['pct_chg'] > 0.01).astype(int)\n",
    "    df['bond_follow_stk_rebound'] = ((df['stk_down_then_up'] == 1) & (df['bond_rebound'] == 1)).astype(int)\n",
    "\n",
    "    # Alpha101 附加因子（转债 & 股票双版本）\n",
    "\n",
    "    # Alpha18: close / rank(mean(close, 20))，动量均值偏离（越大越强）\n",
    "    df['mean_close_20'] = df.groupby('code')['close'].rolling(20).mean().reset_index(level=0, drop=True)\n",
    "    df['rank_mean_close_20'] = df.groupby('trade_date')['mean_close_20'].rank()\n",
    "    df['alpha18'] = df['close'] / df['rank_mean_close_20']\n",
    "\n",
    "    df['mean_close_20_stk'] = df.groupby('code')['close_stk'].rolling(20).mean().reset_index(level=0, drop=True)\n",
    "    df['rank_mean_close_20_stk'] = df.groupby('trade_date')['mean_close_20_stk'].rank()\n",
    "    df['alpha18_stk'] = df['close_stk'] / df['rank_mean_close_20_stk']\n",
    "\n",
    "    # Alpha36: (rank(correlation(vol, close, 5)) + rank(correlation(vol, open, 5)))，量价相关性\n",
    "    df['alpha36'] = df.groupby('code').apply(\n",
    "        lambda x: x['vol'].rolling(5).corr(x['close']) + x['vol'].rolling(5).corr(x['open'])\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    df['alpha36_stk'] = df.groupby('code').apply(\n",
    "        lambda x: x['vol_stk'].rolling(5).corr(x['close_stk']) + x['vol_stk'].rolling(5).corr(x['open_stk'])\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Alpha89: (rank(ts_argmax(close, 30)) / rank(ts_argmin(close, 30)))，反转时机\n",
    "    max_idx = df.groupby('code')['close'].rolling(30).apply(lambda x: 29 - np.argmax(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "    min_idx = df.groupby('code')['close'].rolling(30).apply(lambda x: 29 - np.argmin(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "    df['alpha89'] = max_idx / (min_idx + 1e-9)\n",
    "\n",
    "    max_idx_stk = df.groupby('code')['close_stk'].rolling(30).apply(lambda x: 29 - np.argmax(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "    min_idx_stk = df.groupby('code')['close_stk'].rolling(30).apply(lambda x: 29 - np.argmin(x[::-1]), raw=True).reset_index(level=0, drop=True)\n",
    "    df['alpha89_stk'] = max_idx_stk / (min_idx_stk + 1e-9)\n",
    "\n",
    "    # 使用说明（注释）：\n",
    "    # alpha6, alpha12, alpha83: 反转类因子，基于价格变化和成交量方向识别趋势临界点\n",
    "    # alpha18: 动量偏离（强者恒强）\n",
    "    # alpha36: 量价联动性，适合确认放量跟涨或缩量滞涨\n",
    "    # alpha89: 极端走势时机判断（如低点反转）\n",
    "    # \n",
    "    # 适用于组合：如“价格滞涨 + 正股持续强势 + OBV上升”筛选补涨可转债\n",
    "    # 后续建议使用 evaluate_factors(df, groupby='转股溢价') 分析每组有效性\n",
    "\n",
    "    # Alpha65: correlation(rank(close), rank(vol), 6) → 趋势伴随放量（正相关为强）\n",
    "    df['alpha65'] = df.groupby('code').apply(\n",
    "        lambda x: x['close'].rank().rolling(6).corr(x['vol'].rank())\n",
    "    ).reset_index(level=0, drop=True)\n",
    "    df['alpha65_stk'] = df.groupby('code').apply(\n",
    "        lambda x: x['close_stk'].rank().rolling(6).corr(x['vol_stk'].rank())\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Alpha76: -1 * ts_rank(correlation(close, vol, 10), 10)\n",
    "    df['alpha76'] = df.groupby('code').apply(\n",
    "        lambda x: -1 * x['close'].rolling(10).corr(x['vol']).rolling(10).apply(lambda x: pd.Series(x).rank().iloc[-1])\n",
    "    ).reset_index(level=0, drop=True)\n",
    "    df['alpha76_stk'] = df.groupby('code').apply(\n",
    "        lambda x: -1 * x['close_stk'].rolling(10).corr(x['vol_stk']).rolling(10).apply(lambda x: pd.Series(x).rank().iloc[-1])\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Alpha92: (delta(close, 5)/close) * vol → 回调幅度与量能结合判断洗盘/反转\n",
    "    df['alpha92'] = df.groupby('code').apply(\n",
    "        lambda x: (x['close'].diff(5) / x['close']) * x['vol']\n",
    "    ).reset_index(level=0, drop=True)\n",
    "    df['alpha92_stk'] = df.groupby('code').apply(\n",
    "        lambda x: (x['close_stk'].diff(5) / x['close_stk']) * x['vol_stk']\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Alpha99: -1 * ts_rank(cov(rank(close), rank(vol), 5), 5)\n",
    "    df['alpha99'] = df.groupby('code').apply(\n",
    "        lambda x: -1 * x['close'].rank().rolling(5).cov(x['vol'].rank()).rolling(5).apply(lambda x: pd.Series(x).rank().iloc[-1])\n",
    "    ).reset_index(level=0, drop=True)\n",
    "    df['alpha99_stk'] = df.groupby('code').apply(\n",
    "        lambda x: -1 * x['close_stk'].rank().rolling(5).cov(x['vol_stk'].rank()).rolling(5).apply(lambda x: pd.Series(x).rank().iloc[-1])\n",
    "    ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # =========================\n",
    "    # 📉 可转债-股票反转与回撤风险因子\n",
    "    # =========================\n",
    "\n",
    "    # 1. 可转债 vs 股票 收益强弱横向对比（相对强度）\n",
    "    for win in [3, 5, 10]:\n",
    "        df[f'cb_ret_rank_{win}'] = df.groupby('trade_date')['bond_ret_' + str(win)].rank()\n",
    "        df[f'stk_ret_rank_{win}'] = df.groupby('trade_date')['stk_ret_' + str(win)].rank()\n",
    "        df[f'cb_vs_stk_ret_rank_diff_{win}'] = df[f'cb_ret_rank_{win}'] - df[f'stk_ret_rank_{win}']  # 越高说明转债相对强\n",
    "\n",
    "    # 2. 可转债距近期低点距离（是否已超跌）\n",
    "    df['cb_low_5'] = df.groupby('code')['close'].rolling(5).min().reset_index(level=0, drop=True)\n",
    "    df['cb_dev_from_low_5'] = (df['close'] - df['cb_low_5']) / df['cb_low_5']  # 越大说明已反弹\n",
    "\n",
    "    # 3. 可转债价格波动性（风险识别）\n",
    "    df['cb_close_std_5'] = df.groupby('code')['close'].rolling(5).std().reset_index(level=0, drop=True)\n",
    "\n",
    "    # 4. 可转债近5日最大回撤（最高点到当前）\n",
    "    df['cb_high_5'] = df.groupby('code')['close'].rolling(5).max().reset_index(level=0, drop=True)\n",
    "    df['cb_drawdown_5'] = (df['close'] - df['cb_high_5']) / df['cb_high_5']  # 越负说明风险释放\n",
    "\n",
    "    # 5. 下跌风险预估（历史概率 × 幅度）\n",
    "    df['cb_ret_1'] = df.groupby('code')['pct_chg'].shift(1)\n",
    "    df['cb_fall_flag'] = (df['cb_ret_1'] < 0).astype(int)\n",
    "    df['cb_fall_freq_10'] = df.groupby('code')['cb_fall_flag'].rolling(10).mean().reset_index(level=0, drop=True)\n",
    "    df['cb_fall_amp_10'] = df.groupby('code')['cb_ret_1'].rolling(10).apply(lambda x: x[x < 0].mean() if (x < 0).any() else 0).reset_index(level=0, drop=True)\n",
    "    df['cb_dd_prob_estimate'] = df['cb_fall_freq_10'] * df['cb_fall_amp_10']  # 越负风险越大\n",
    "\n",
    "    df['high_jump'] = (df['high'] / df['pre_close'] - 1) > 0.025\n",
    "    df['low_gap'] = (df['low'] / df['pre_close'] - 1) < -0.025\n",
    "    df['open_jump'] = (df['open'] / df['pre_close'] - 1).abs()\n",
    "    df['gap_body_ratio'] = (df['open'] - df['pre_close']) / (df['close'] - df['open']).replace(0, np.nan)\n",
    "\n",
    "    for win in [20, 100, 250]:\n",
    "        df[f'high_jump_count_{win}'] = df.groupby('code')['high_jump'].rolling(window=win, min_periods=1).sum().reset_index(0, drop=True)\n",
    "        df[f'low_gap_count_{win}'] = df.groupby('code')['low_gap'].rolling(window=win, min_periods=1).sum().reset_index(0, drop=True)\n",
    "        df[f'high_jump_count_{win}_pct'] = df.groupby('trade_date')[f'high_jump_count_{win}'].rank(pct=True)\n",
    "        df[f'low_gap_count_{win}_pct'] = df.groupby('trade_date')[f'low_gap_count_{win}'].rank(pct=True)\n",
    "        df.loc[df[f'high_jump_count_{win}_pct'] < 0.1, 'filter'] = True\n",
    "\n",
    "    # 收盘价与高低点关系\n",
    "    df['close_to_high_ratio'] = (df['close'] - df['low']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "    df['close_to_low_ratio'] = (df['high'] - df['close']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "    df['body_position'] = (df['close'] - df['open']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "    df['upper_shadow_ratio'] = (df['high'] - df[['close', 'open']].max(axis=1)) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "    df['lower_shadow_ratio'] = (df[['close', 'open']].min(axis=1) - df['low']) / (df['high'] - df['low']).replace(0, np.nan)\n",
    "\n",
    "\n",
    "\n",
    "    # 新增部分：涨不动 + 跌不动 + 脉冲可能性因子组合（含补充因子）\n",
    "# =========================\n",
    "\n",
    "# 1. 涨不动 & 跌不动（震荡收敛类）\n",
    "# -----------------------------------\n",
    "# ATR 衰减率（震荡幅度变窄）\n",
    "    df['atr_5'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "    df['atr_20'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(20).mean()).reset_index(0, drop=True)\n",
    "    df['atr_5_decay'] = df['atr_5'] / df['atr_20']\n",
    "\n",
    "# 振幅衰减（高低价差缩小）\n",
    "    df['zhengfu_5'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "    df['zhengfu_20'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(20).mean()).reset_index(0, drop=True)\n",
    "    df['zhengfu_decay_5_20'] = df['zhengfu_5'] / df['zhengfu_20']\n",
    "\n",
    "# 高低价差比均值\n",
    "    range_5 = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "    range_20 = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(20).mean()).reset_index(0, drop=True)\n",
    "    df['range_ratio_5_20'] = range_5 / range_20\n",
    "\n",
    "# 极小实体 + 长影线结构\n",
    "    body = (df['close'] - df['open']).abs()\n",
    "    shadow = (df['high'] - df['low']) - body\n",
    "    df['small_body_shadow_ratio'] = shadow / (body + 1e-6)\n",
    "\n",
    "# 十字星出现频率\n",
    "    is_doji = (body / (df['high'] - df['low'] + 1e-6)) < 0.15\n",
    "    df['doji_ratio_5'] = is_doji.groupby(df['code']).rolling(5).mean().reset_index(0, drop=True)\n",
    "\n",
    "# 2. 脉冲概率 × 脉冲幅度 × 情绪波动\n",
    "# -----------------------------------\n",
    "# high_jump 多档位\n",
    "    for thres in [0.015, 0.02, 0.03, 0.04, 0.05, 0.06]:\n",
    "        df[f'high_jump_{int(thres*1000)}'] = ((df['high'] / df['pre_close'] - 1) > thres).astype(int)\n",
    "        df[f'count_high_jump_{int(thres*1000)}_20'] = df.groupby('code')[f'high_jump_{int(thres*1000)}'].rolling(20).sum().reset_index(0, drop=True)\n",
    "        df[f'mean_high_jump_{int(thres*1000)}_20'] = df.groupby('code')['pct_chg'].where(df[f'high_jump_{int(thres*1000)}'] == 1).rolling(20).mean().reset_index(0, drop=True)\n",
    "        df[f'score_high_jump_{int(thres*1000)}_20'] = df[f'count_high_jump_{int(thres*1000)}_20'] * df[f'mean_high_jump_{int(thres*1000)}_20']\n",
    "\n",
    "# 脉冲 Z-score（涨幅异常性）\n",
    "    df['zscore_pctchg_20'] = df.groupby('code')['pct_chg'].transform(lambda x: (x - x.rolling(20).mean()) / (x.rolling(20).std() + 1e-6))\n",
    "\n",
    "# 成交量脉冲\n",
    "    vol_ma20 = df.groupby('code')['vol'].rolling(20).mean().reset_index(0, drop=True)\n",
    "    df['vol_spike_ratio'] = df['vol'] / (vol_ma20 + 1e-6)\n",
    "\n",
    "# 成交量波动收敛\n",
    "    vol_std_5 = df.groupby('code')['vol'].rolling(5).std().reset_index(0, drop=True)\n",
    "    vol_std_20 = df.groupby('code')['vol'].rolling(20).std().reset_index(0, drop=True)\n",
    "    df['vol_std_decay'] = vol_std_5 / (vol_std_20 + 1e-6)\n",
    "\n",
    "# 3. 脉冲持续性（跳空+阳线）\n",
    "# -----------------------------------\n",
    "    df['gap_and_go_flag'] = ((df['open'] > df['pre_close'] * 1.02) & (df['close'] > df['open'])).astype(int)\n",
    "    df['gap_body_ratio'] = (df['open'] - df['pre_close']) / (df['close'] - df['open']).replace(0, np.nan)\n",
    "    df.to_parquet('/Users/yiwei/Desktop/git/cb_data_with_factors.pq')\n",
    "\n",
    "\n",
    "\n",
    "    # 新增部分：涨不动 + 跌不动 + 脉冲可能性因子组合\n",
    "# =========================\n",
    "\n",
    "# 1. 涨不动 & 跌不动（震荡收敛类）\n",
    "# -----------------------------------\n",
    "# ATR 衰减率（震荡幅度变窄）\n",
    "    df['atr_5'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "    df['atr_10'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(10).mean()).reset_index(0, drop=True)\n",
    "    df['atr_decay_5_10'] = df['atr_5'] / df['atr_10']  # 趋近 1 为震荡，远小于 1 为收敛\n",
    "\n",
    "# 收盘价波动率缩小（标准差下降）\n",
    "    df['close_std_5'] = df.groupby('code')['close'].rolling(5).std().reset_index(0, drop=True)\n",
    "    df['close_std_10'] = df.groupby('code')['close'].rolling(10).std().reset_index(0, drop=True)\n",
    "    df['vol_shrink_ratio'] = df['close_std_5'] / df['close_std_10']  # 小于1说明震荡收敛\n",
    "\n",
    "# K线实体变短（绝对涨跌幅变小）\n",
    "    df['body_pct'] = (df['close'] - df['open']).abs() / df['pre_close']\n",
    "    df['body_pct_mean_5'] = df.groupby('code')['body_pct'].rolling(5).mean().reset_index(0, drop=True)\n",
    "\n",
    "# 上下影线增多（震荡特征）\n",
    "    df['shadow_ratio'] = ((df['high'] - df['low']) - (df['close'] - df['open']).abs()) / df['pre_close']\n",
    "    df['shadow_mean_5'] = df.groupby('code')['shadow_ratio'].rolling(5).mean().reset_index(0, drop=True)\n",
    "\n",
    "# 2. 脉冲概率 × 脉冲幅度\n",
    "# -----------------------------------\n",
    "# high_jump 多阈值\n",
    "    for thres in [0.015, 0.02, 0.03, 0.04, 0.05, 0.06]:\n",
    "        df[f'high_jump_{int(thres*1000)}'] = ((df['high'] / df['pre_close'] - 1) > thres).astype(int)\n",
    "\n",
    "# 跳空幅度（带方向）统计\n",
    "    for n in [5, 10]:\n",
    "        df[f'open_gap_mean_{n}'] = df.groupby('code')['open_jump'].rolling(n).mean().reset_index(0, drop=True)\n",
    "        df[f'open_gap_max_{n}'] = df.groupby('code')['open_jump'].rolling(n).max().reset_index(0, drop=True)\n",
    "\n",
    "# N 日脉冲 ATR：高点远离均值（短期剧烈拉升）\n",
    "    for n in [3, 5, 10]:\n",
    "        high_mean = df.groupby('code')['high'].rolling(n).mean().reset_index(0, drop=True)\n",
    "        close_mean = df.groupby('code')['close'].rolling(n).mean().reset_index(0, drop=True)\n",
    "        df[f'jump_atr_{n}'] = (df['high'] - close_mean) / (df.groupby('code')['close'].rolling(n).std().reset_index(0, drop=True) + 1e-6)\n",
    "\n",
    "# 3. 跌不动（下跌概率低 + 幅度小）\n",
    "# -----------------------------------\n",
    "    for win in [5, 10]:\n",
    "        df[f'down_freq_{win}'] = df.groupby('code')['pct_chg'].apply(lambda x: x.rolling(win).apply(lambda s: (s < 0).mean())).reset_index(0, drop=True)\n",
    "        df[f'down_amp_{win}'] = df.groupby('code')['pct_chg'].apply(lambda x: x.rolling(win).apply(lambda s: s[s < 0].mean() if (s < 0).any() else 0)).reset_index(0, drop=True)\n",
    "        df[f'no_fall_score_{win}'] = (1 - df[f'down_freq_{win}']) * (-df[f'down_amp_{win}'])  # 越大越“跌不动”\n",
    "\n",
    "# 4. 高脉冲动能（high_jump / atr / shadow 等集中爆发）\n",
    "# -----------------------------------\n",
    "    df['range_today'] = df['high'] - df['low']\n",
    "    df['range_atr_5'] = df['range_today'] / df.groupby('code')['range_today'].rolling(5).mean().reset_index(0, drop=True)\n",
    "    df['range_jump_potential'] = (df['range_atr_5'] > 1.5).astype(int)\n",
    "\n",
    "# 5. K线结构连续性判断（阴阳交错、跳空接力）\n",
    "# -----------------------------------\n",
    "    df['kline_direction'] = np.sign(df['close'] - df['open'])\n",
    "    df['kline_direction_shift1'] = df.groupby('code')['kline_direction'].shift(1)\n",
    "    df['kline_flip'] = (df['kline_direction'] * df['kline_direction_shift1'] < 0).astype(int)\n",
    "    df['kline_flip_ratio_5'] = df.groupby('code')['kline_flip'].rolling(5).mean().reset_index(0, drop=True)  # 多为 0 则趋势稳定\n",
    "\n",
    "# =========================\n",
    "# 所有新增字段在后续可组合使用：如（涨不动 + 跌不动 + low_gap_count 小）识别蓄力震荡；或（脉冲概率高 × 最近收敛）识别爆发行情前兆\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions (safe_division, rolling_downside_stats, rolling_high_jump_stats)\n",
    "# ... (keep the helper functions as they were) ...\n",
    "def safe_division(numerator, denominator, default=np.nan):\n",
    "    \"\"\"Performs division, returning default value if denominator is zero or NaN.\"\"\"\n",
    "    denominator = denominator.replace(0, np.nan)\n",
    "    result = numerator / denominator\n",
    "    return result.fillna(default)\n",
    "\n",
    "def rolling_downside_stats(series, window):\n",
    "    \"\"\"Calculates downside frequency, mean amplitude, and std amplitude.\"\"\"\n",
    "    is_down = series < 0\n",
    "    freq = is_down.rolling(window, min_periods=max(1, int(window * 0.6))).mean().fillna(0)\n",
    "    down_series = series.where(is_down)\n",
    "    mean_amp = down_series.rolling(window, min_periods=max(1, int(window * 0.6))).mean().fillna(0)\n",
    "    std_amp = down_series.rolling(window, min_periods=max(2, int(window * 0.6))).std().fillna(0)\n",
    "    return freq, mean_amp, std_amp\n",
    "\n",
    "def rolling_high_jump_stats(jump_flag, pct_chg, window):\n",
    "    \"\"\"Calculates high jump count, mean jump return, and std jump return.\"\"\"\n",
    "    count = jump_flag.rolling(window, min_periods=max(1, int(window * 0.6))).sum().fillna(0)\n",
    "    jump_returns = pct_chg.where(jump_flag)\n",
    "    mean_ret = jump_returns.rolling(window, min_periods=max(1, int(window * 0.6))).mean().fillna(0)\n",
    "    std_ret = jump_returns.rolling(window, min_periods=max(2, int(window * 0.6))).std().fillna(0)\n",
    "    return count, mean_ret, std_ret\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "def calculate_factors(df, restore_multiindex=False): # Added option to restore index\n",
    "    \"\"\"\n",
    "    Calculates convertible bond and corresponding stock factors based on the checklist.\n",
    "    Handles DataFrame with 'code' and 'trade_date' as columns OR MultiIndex levels.\n",
    "    Excludes rank, percentage rank (pct=True), and explicit 'score_' factors.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        restore_multiindex (bool): If True, sets ['code', 'trade_date'] back as index at the end.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added factor columns.\n",
    "    \"\"\"\n",
    "    print(\"Starting factor calculation...\")\n",
    "\n",
    "    # --- Input Validation and Index Handling ---\n",
    "    has_code_col = 'code' in df.columns\n",
    "    has_date_col = 'trade_date' in df.columns\n",
    "    has_code_idx = 'code' in df.index.names\n",
    "    has_date_idx = 'trade_date' in df.index.names\n",
    "\n",
    "    if has_code_col and has_date_col:\n",
    "        print(\"Found 'code' and 'trade_date' in columns.\")\n",
    "        # Sort directly if columns exist\n",
    "        df = df.sort_values(by=['code', 'trade_date']).copy() # Use copy to avoid SettingWithCopyWarning later\n",
    "    elif has_code_idx and has_date_idx:\n",
    "        print(\"Found 'code' and 'trade_date' in MultiIndex. Resetting index.\")\n",
    "        df = df.reset_index()\n",
    "        # Now sort by the newly created columns\n",
    "        df = df.sort_values(by=['code', 'trade_date']).copy() # Use copy\n",
    "    else:\n",
    "        missing = []\n",
    "        if not (has_code_col or has_code_idx):\n",
    "            missing.append('code')\n",
    "        if not (has_date_col or has_date_idx):\n",
    "            missing.append('trade_date')\n",
    "        raise ValueError(f\"DataFrame must contain 'code' and 'trade_date' either as columns or index levels. Missing: {missing}\")\n",
    "    # --- End Index Handling ---\n",
    "\n",
    "\n",
    "    # 0. Data Type Preparation & Safety\n",
    "    base_cols = ['high', 'low', 'close', 'open', 'vol', 'pre_close', 'pct_chg', 'turnover', 'remain_cap', 'float_share']\n",
    "    stk_cols = ['high_stk', 'low_stk', 'close_stk', 'open_stk', 'vol_stk', 'pct_chg_stk']\n",
    "    # Include 'code', 'trade_date' now they are guaranteed columns\n",
    "    all_req_cols = base_cols + stk_cols + ['code', 'trade_date']\n",
    "\n",
    "    for col in all_req_cols:\n",
    "        if col in df.columns:\n",
    "            # Don't coerce code/date if they became columns\n",
    "            if col not in ['code', 'trade_date']:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce') # Convert non-numeric to NaN\n",
    "                df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        # else: # Removed redundant check as missing cols are handled by later logic gracefully\n",
    "        #    print(f\"Warning: Column '{col}' not found in DataFrame.\")\n",
    "\n",
    "\n",
    "    # === Factor Calculations Start Here ===\n",
    "    # The rest of the code (Sections I to XVI) remains exactly the same\n",
    "    # as it now operates on a DataFrame where 'code' and 'trade_date'\n",
    "    # are guaranteed to be columns, and the data is sorted.\n",
    "    # ======================================\n",
    "\n",
    "    # === I. Basic Price & Volatility (CB) ===\n",
    "    print(\"Calculating: I. Basic Price & Volatility (CB)\")\n",
    "    df['ma_20'] = df.groupby('code')['close'].transform(lambda x: ta.SMA(x, timeperiod=20))\n",
    "    df['momentum_20'] = df.groupby('code')['close'].transform(lambda x: safe_division(x, x.shift(20)))\n",
    "    df['volatility_20'] = df.groupby('code')['close'].transform(lambda x: x.rolling(20, min_periods=10).std())\n",
    "    df['max_value'] = df.groupby('code')['close'].transform(lambda x: x.cummax().shift(1))\n",
    "    df['max_value_position'] = safe_division(df['close'], df['max_value'])\n",
    "    if 'high' in df.columns and 'low' in df.columns and 'close' in df.columns:\n",
    "        df['zhengfu'] = safe_division(df['high'] - df['low'], df['close'])\n",
    "        df['zhengfu_cha'] = safe_division(df['high'] - df['close'], (df['open'] - df['close']).abs())\n",
    "        # NATR - Needs apply which handles MultiIndex implicitly if we hadn't reset\n",
    "        # Since we reset, groupby('code').apply works fine\n",
    "        df['natr_14'] = df.groupby('code').apply(lambda x: ta.NATR(x['high'], x['low'], x['close'], timeperiod=14) if not x[['high','low','close']].isnull().all().all() else pd.Series(index=x.index, dtype=float)).reset_index(level=0, drop=True)\n",
    "        for n in [1, 3, 5, 10, 20]:\n",
    "             df[f'natr_{n}'] = df.groupby('code').apply(lambda x: ta.NATR(x['high'], x['low'], x['close'], timeperiod=n) if not x[['high','low','close']].isnull().all().all() else pd.Series(index=x.index, dtype=float)).reset_index(level=0, drop=True)\n",
    "    # Future return (Label)\n",
    "    df['aft_high1'] = df.groupby('code')['high'].shift(-1)\n",
    "    df['aft_high_cur_close'] = safe_division(df['aft_high1'] - df['close'], df['close'])\n",
    "\n",
    "\n",
    "    # === II. OBV (CB) ===\n",
    "    print(\"Calculating: II. OBV (CB)\")\n",
    "    if 'close' in df.columns and 'vol' in df.columns:\n",
    "        df['obv'] = df.groupby('code').apply(lambda x: ta.OBV(x['close'], x['vol']) if not x[['close','vol']].isnull().all().all() else pd.Series(index=x.index, dtype=float)).reset_index(level=0, drop=True)\n",
    "        df['obv_5'] = df.groupby('code')['obv'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "        df['obv_10'] = df.groupby('code')['obv'].transform(lambda x: x.rolling(10, min_periods=5).mean())\n",
    "        df['obv_ratio_5_10'] = safe_division(df['obv_5'], df['obv_10'])\n",
    "\n",
    "\n",
    "    # === III. Turnover & Cap ===\n",
    "    print(\"Calculating: III. Turnover & Cap\")\n",
    "    print(\"  - Skipping: turnover_pct, rolling_*_avg, rolling_*_to_*_avg (rank/pct based)\")\n",
    "    if 'turnover' in df.columns:\n",
    "        for win in [5, 10, 20, 60]:\n",
    "            df[f'turnover_{win}_avg'] = df.groupby('code')['turnover'].transform(lambda x: x.rolling(window=win, min_periods=int(win*0.6)).mean())\n",
    "    if all(col in df.columns for col in ['remain_cap', 'float_share', 'close_stk']):\n",
    "        df['cap_float_share_rate'] = safe_division(df['remain_cap'] * 10000, (df['float_share'] * df['close_stk']))\n",
    "\n",
    "\n",
    "    # === IV. Rolling Returns (CB & Stock) ===\n",
    "    print(\"Calculating: IV. Rolling Returns (CB & Stock)\")\n",
    "    if 'pct_chg' in df.columns:\n",
    "        for win in [3, 5, 10, 20]:\n",
    "            df[f'pct_chg_{win}'] = df.groupby('code')['pct_chg'].transform(\n",
    "                lambda x: (x + 1).rolling(win, min_periods=max(1,int(win*0.6))).apply(np.prod, raw=True) - 1\n",
    "            )\n",
    "            df[f'bond_ret_mean_{win}'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(win, min_periods=max(1,int(win*0.6))).mean())\n",
    "\n",
    "    if 'pct_chg_stk' in df.columns:\n",
    "        for win in [3, 5, 10, 20]:\n",
    "            df[f'pct_chg_stk_{win}'] = df.groupby('code')['pct_chg_stk'].transform(\n",
    "                lambda x: (x + 1).rolling(win, min_periods=max(1,int(win*0.6))).apply(np.prod, raw=True) - 1\n",
    "            )\n",
    "            df[f'stk_ret_mean_{win}'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(win, min_periods=max(1,int(win*0.6))).mean())\n",
    "\n",
    "\n",
    "    # === V. Volume Avg Ratio (CB) ===\n",
    "    print(\"Calculating: V. Volume Avg Ratio (CB)\")\n",
    "    if 'vol' in df.columns:\n",
    "        vol_windows = [3, 5, 10, 20, 30, 60]\n",
    "        for n in vol_windows:\n",
    "            df[f'vol_{n}_avg'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(n, min_periods=int(n*0.6)).mean())\n",
    "        for n in vol_windows:\n",
    "            for m in vol_windows:\n",
    "                if n < m and f'vol_{n}_avg' in df.columns and f'vol_{m}_avg' in df.columns:\n",
    "                    df[f'vol_{n}_to_{m}'] = safe_division(df[f'vol_{n}_avg'], df[f'vol_{m}_avg'])\n",
    "\n",
    "\n",
    "    # === VI. Volatility & Amplitude (CB & Stock) ===\n",
    "    print(\"Calculating: VI. Volatility & Amplitude (CB & Stock)\")\n",
    "    if 'pct_chg_stk' in df.columns:\n",
    "        for win in [5, 10, 20, 60]:\n",
    "            df[f'bodong_{win}'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(win, min_periods=int(win*0.6)).std() * (win ** 0.5))\n",
    "        if 'bodong_20' in df.columns and 'bodong_60' in df.columns:\n",
    "            df['bodong_20_to_bodong_60'] = safe_division(df['bodong_20'], df['bodong_60'])\n",
    "\n",
    "    if 'pct_chg' in df.columns:\n",
    "        for win in [5, 10, 20, 60]:\n",
    "             df[f'bodong_{win}_bd'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(win, min_periods=int(win*0.6)).std() * (win ** 0.5))\n",
    "\n",
    "    if 'zhengfu' in df.columns:\n",
    "        for win in [1, 5, 10, 20, 60]:\n",
    "            df[f'zhengfu_{win}'] = df.groupby('code')['zhengfu'].transform(lambda x: x.rolling(win, min_periods=max(1,int(win*0.6))).std())\n",
    "            df[f'zhengfu_{win}_bodong'] = df[f'zhengfu_{win}'] * (win ** 0.5)\n",
    "\n",
    "\n",
    "    # === VII. Jump & Gap (CB) ===\n",
    "    print(\"Calculating: VII. Jump & Gap (CB)\")\n",
    "    print(\"  - Skipping: high_jump_count_*_pct, low_gap_count_*_pct (pct based)\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'open', 'close', 'pre_close']):\n",
    "        # Use a temp name to avoid conflict later if needed\n",
    "        df['_high_jump_flag_temp'] = (safe_division(df['high'], df['pre_close']) - 1) > 0.025\n",
    "        df['_low_gap_flag_temp'] = (safe_division(df['low'], df['pre_close']) - 1) < -0.025\n",
    "        df['open_jump'] = (safe_division(df['open'], df['pre_close']) - 1).abs()\n",
    "        df['gap_body_ratio'] = safe_division(df['open'] - df['pre_close'], (df['close'] - df['open']))\n",
    "\n",
    "        for win in [20, 100, 250]:\n",
    "             df[f'high_jump_count_{win}'] = df.groupby('code')['_high_jump_flag_temp'].transform(lambda x: x.rolling(window=win, min_periods=int(win*0.6)).sum())\n",
    "             df[f'low_gap_count_{win}'] = df.groupby('code')['_low_gap_flag_temp'].transform(lambda x: x.rolling(window=win, min_periods=int(win*0.6)).sum())\n",
    "\n",
    "\n",
    "    # === VIII. K-Line Structure (CB) ===\n",
    "    print(\"Calculating: VIII. K-Line Structure (CB)\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'open', 'close']):\n",
    "        high_low_diff = (df['high'] - df['low']).replace(0, np.nan)\n",
    "        df['close_to_high_ratio'] = safe_division(df['close'] - df['low'], high_low_diff)\n",
    "        df['close_to_low_ratio'] = safe_division(df['high'] - df['close'], high_low_diff)\n",
    "        df['body_position'] = safe_division(df['close'] - df['open'], high_low_diff)\n",
    "        df['upper_shadow_ratio'] = safe_division(df['high'] - df[['close', 'open']].max(axis=1), high_low_diff)\n",
    "        df['lower_shadow_ratio'] = safe_division(df[['close', 'open']].min(axis=1) - df['low'], high_low_diff)\n",
    "\n",
    "\n",
    "    # === IX. Trend Reversal Alpha Factors (CB & Stock) ===\n",
    "    print(\"Calculating: IX. Trend Reversal Alpha Factors (CB & Stock)\")\n",
    "    print(\"  - Skipping: alpha6, alpha18, alpha65, alpha76, alpha99 (rank based)\")\n",
    "    df['delta_vol_1'] = df.groupby('code')['vol'].transform(lambda x: x.diff(1))\n",
    "    df['delta_close_1'] = df.groupby('code')['close'].transform(lambda x: x.diff(1))\n",
    "    df['delta_close_5'] = df.groupby('code')['close'].transform(lambda x: x.diff(5))\n",
    "    if 'vol_stk' in df.columns:\n",
    "        df['delta_vol_1_stk'] = df.groupby('code')['vol_stk'].transform(lambda x: x.diff(1))\n",
    "    if 'close_stk' in df.columns:\n",
    "        df['delta_close_1_stk'] = df.groupby('code')['close_stk'].transform(lambda x: x.diff(1))\n",
    "        df['delta_close_5_stk'] = df.groupby('code')['close_stk'].transform(lambda x: x.diff(5))\n",
    "\n",
    "    # Alpha12\n",
    "    if all(c in df.columns for c in ['delta_vol_1', 'delta_close_1']):\n",
    "        df['alpha12'] = np.sign(df['delta_vol_1']) * -1 * df['delta_close_1']\n",
    "    if all(c in df.columns for c in ['delta_vol_1_stk', 'delta_close_1_stk']):\n",
    "        df['alpha12_stk'] = np.sign(df['delta_vol_1_stk']) * -1 * df['delta_close_1_stk']\n",
    "\n",
    "    # # Alpha83 (Days since 30d high)\n",
    "    # df['alpha83'] = df.groupby('code')['close'].transform(\n",
    "    #     lambda x: x.rolling(30, min_periods=15).apply(lambda s: 29 - np.argmax(s.to_numpy()[::-1]) if not s.isnull().all() else np.nan, raw=True)\n",
    "    # )\n",
    "    # if 'close_stk' in df.columns:\n",
    "    #     df['alpha83_stk'] = df.groupby('code')['close_stk'].transform(\n",
    "    #         lambda x: x.rolling(30, min_periods=15).apply(lambda s: 29 - np.argmax(s.to_numpy()[::-1]) if not s.isnull().all() else np.nan, raw=True)\n",
    "    #     )\n",
    "\n",
    "    # === IX. Trend Reversal Alpha Factors (CB & Stock) ===\n",
    "    print(\"Calculating: IX. Trend Reversal Alpha Factors (CB & Stock)\")\n",
    "    # ... (other alpha calculations before 83) ...\n",
    "\n",
    "    # Alpha83 (Days since 30d high) - Corrected\n",
    "    print(\"  - Calculating alpha83...\")\n",
    "    df['alpha83'] = df.groupby('code')['close'].transform(\n",
    "        lambda x: x.rolling(30, min_periods=15).apply(\n",
    "            lambda s: (len(s) - 1) - np.nanargmax(s.to_numpy()) if not s.isnull().all() else np.nan,\n",
    "            raw=False # <--- REMOVED raw=True, forces s to be a Series\n",
    "        )\n",
    "    )\n",
    "    # Also corrected the logic: days_ago = window_size - 1 - position_of_max\n",
    "    # np.nanargmax ignores NaNs and finds the position of the first max\n",
    "\n",
    "    if 'close_stk' in df.columns:\n",
    "        print(\"  - Calculating alpha83_stk...\")\n",
    "        df['alpha83_stk'] = df.groupby('code')['close_stk'].transform(\n",
    "            lambda x: x.rolling(30, min_periods=15).apply(\n",
    "                lambda s: (len(s) - 1) - np.nanargmax(s.to_numpy()) if not s.isnull().all() else np.nan,\n",
    "                raw=False # <--- REMOVED raw=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Alpha36 (Volume-Price Correlation)\n",
    "    if all(c in df.columns for c in ['vol', 'close', 'open']):\n",
    "        # transform with rolling corr can be tricky with multiple columns, use apply carefully\n",
    "        def calc_alpha36(x):\n",
    "             corr_close = x['vol'].rolling(5, min_periods=3).corr(x['close'])\n",
    "             corr_open = x['vol'].rolling(5, min_periods=3).corr(x['open'])\n",
    "             return corr_close.add(corr_open, fill_value=0)\n",
    "        df['alpha36'] = df.groupby('code', group_keys=False).apply(calc_alpha36)\n",
    "\n",
    "    if all(c in df.columns for c in ['vol_stk', 'close_stk', 'open_stk']):\n",
    "        def calc_alpha36_stk(x):\n",
    "             corr_close = x['vol_stk'].rolling(5, min_periods=3).corr(x['close_stk'])\n",
    "             corr_open = x['vol_stk'].rolling(5, min_periods=3).corr(x['open_stk'])\n",
    "             return corr_close.add(corr_open, fill_value=0)\n",
    "        df['alpha36_stk'] = df.groupby('code', group_keys=False).apply(calc_alpha36_stk)\n",
    "\n",
    "\n",
    "    # # Alpha89 (High position / Low position)\n",
    "    # df['argmin_close_30_idx'] = df.groupby('code')['close'].transform(\n",
    "    #     lambda x: x.rolling(30, min_periods=15).apply(lambda s: 29 - np.argmin(s.to_numpy()[::-1]) if not s.isnull().all() else np.nan, raw=True)\n",
    "    # )\n",
    "    # if 'alpha83' in df.columns: # Check dependencies\n",
    "    #     df['alpha89'] = safe_division(df['alpha83'], df['argmin_close_30_idx'])\n",
    "\n",
    "    # if 'close_stk' in df.columns:\n",
    "    #     df['argmin_close_30_idx_stk'] = df.groupby('code')['close_stk'].transform(\n",
    "    #          lambda x: x.rolling(30, min_periods=15).apply(lambda s: 29 - np.argmin(s.to_numpy()[::-1]) if not s.isnull().all() else np.nan, raw=True)\n",
    "    #     )\n",
    "    #     if 'alpha83_stk' in df.columns: # Check dependencies\n",
    "    #         df['alpha89_stk'] = safe_division(df['alpha83_stk'], df['argmin_close_30_idx_stk'])\n",
    "\n",
    "    # Alpha89 (High position / Low position) - Also update this to use correct logic\n",
    "    print(\"  - Calculating alpha89 (dependent on corrected alpha83)...\")\n",
    "    df['argmin_close_30_idx_pos'] = df.groupby('code')['close'].transform( # Calculate days since min\n",
    "        lambda x: x.rolling(30, min_periods=15).apply(\n",
    "            lambda s: (len(s) - 1) - np.nanargmin(s.to_numpy()) if not s.isnull().all() else np.nan,\n",
    "            raw=False\n",
    "        )\n",
    "    )\n",
    "    if 'alpha83' in df.columns: # Check dependencies\n",
    "        # alpha89 = (days since high) / (days since low + epsilon)\n",
    "        # Smaller value means high is recent relative to low\n",
    "        df['alpha89'] = safe_division(df['alpha83'], df['argmin_close_30_idx_pos'])\n",
    "\n",
    "    if 'close_stk' in df.columns:\n",
    "        df['argmin_close_30_idx_pos_stk'] = df.groupby('code')['close_stk'].transform(\n",
    "             lambda x: x.rolling(30, min_periods=15).apply(\n",
    "                 lambda s: (len(s) - 1) - np.nanargmin(s.to_numpy()) if not s.isnull().all() else np.nan,\n",
    "                 raw=False\n",
    "             )\n",
    "        )\n",
    "        if 'alpha83_stk' in df.columns: # Check dependencies\n",
    "            df['alpha89_stk'] = safe_division(df['alpha83_stk'], df['argmin_close_30_idx_pos_stk'])\n",
    "\n",
    "    # Alpha92 (Price Change * Volume)\n",
    "    if all(c in df.columns for c in ['delta_close_5', 'close', 'vol']):\n",
    "        df['alpha92'] = safe_division(df['delta_close_5'], df['close']) * df['vol']\n",
    "    if all(c in df.columns for c in ['delta_close_5_stk', 'close_stk', 'vol_stk']):\n",
    "        df['alpha92_stk'] = safe_division(df['delta_close_5_stk'], df['close_stk']) * df['vol_stk']\n",
    "\n",
    "\n",
    "    # === X. Stock & CB Linkage ===\n",
    "    print(\"Calculating: X. Stock & CB Linkage\")\n",
    "    if 'pct_chg' in df.columns and 'pct_chg_stk' in df.columns:\n",
    "        df['stk_up_bond_flat'] = ((df['pct_chg_stk'] > 0.03) & (df['pct_chg'] < 0.01)).astype(int)\n",
    "        df['stk_down_bond_weak'] = ((df['pct_chg_stk'] < -0.03) & (df['pct_chg'] < df['pct_chg_stk'])).astype(int)\n",
    "        # Lagged vars\n",
    "        df['pct_chg_stk_lag1'] = df.groupby('code')['pct_chg_stk'].shift(1)\n",
    "        df['pct_chg_stk_lag2'] = df.groupby('code')['pct_chg_stk'].shift(2)\n",
    "        # Check if lags were created before using them\n",
    "        if 'pct_chg_stk_lag1' in df.columns:\n",
    "            df['bond_hold_stk_rebound'] = ((df['pct_chg_stk_lag1'] < -0.03) & (df['pct_chg_stk'] > 0.01) & (df['pct_chg'] > 0.005)).astype(int)\n",
    "        if 'pct_chg_stk_lag2' in df.columns:\n",
    "            df['stk_down_then_up'] = ((df['pct_chg_stk_lag2'] < -0.03) & (df['pct_chg_stk'] > 0.02)).astype(int)\n",
    "        df['bond_rebound'] = (df['pct_chg'] > 0.01).astype(int)\n",
    "        if 'stk_down_then_up' in df.columns: # Check dependency\n",
    "            df['bond_follow_stk_rebound'] = ((df['stk_down_then_up'] == 1) & (df['bond_rebound'] == 1)).astype(int)\n",
    "        # Multi-day linkage\n",
    "        if all(c in df.columns for c in ['stk_ret_mean_3', 'bond_ret_mean_3']):\n",
    "             df['stk_up_bond_flat_3'] = ((df['stk_ret_mean_3'] > 0.01) & (df['bond_ret_mean_3'] < 0.003)).astype(int)\n",
    "        if all(c in df.columns for c in ['stk_ret_mean_5', 'bond_ret_mean_5']):\n",
    "             df['stk_up_bond_flat_5'] = ((df['stk_ret_mean_5'] > 0.015) & (df['bond_ret_mean_5'] < 0.005)).astype(int)\n",
    "\n",
    "\n",
    "    # === XI. Horizontal & Vertical Deviation ===\n",
    "    print(\"Calculating: XI. Horizontal & Vertical Deviation\")\n",
    "    print(\"  - Skipping: cb_vs_stk_ret_rank_diff (rank based)\")\n",
    "    for win in [3, 5, 10]:\n",
    "        if f'bond_ret_mean_{win}' in df.columns and f'stk_ret_mean_{win}' in df.columns:\n",
    "            df[f'dev_bond_vs_stk_{win}'] = df[f'bond_ret_mean_{win}'] - df[f'stk_ret_mean_{win}']\n",
    "\n",
    "    # Vertical requires longer term means calculated here\n",
    "    if 'pct_chg' in df.columns:\n",
    "        df['bond_ret_mean_20'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['bond_ret_mean_30'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(30, min_periods=18).mean())\n",
    "        if 'bond_ret_mean_3' in df.columns and 'bond_ret_mean_20' in df.columns:\n",
    "            df['dev_bond_short3_long20'] = df['bond_ret_mean_3'] - df['bond_ret_mean_20']\n",
    "        if 'bond_ret_mean_5' in df.columns and 'bond_ret_mean_30' in df.columns:\n",
    "            df['dev_bond_short5_long30'] = df['bond_ret_mean_5'] - df['bond_ret_mean_30']\n",
    "\n",
    "    if 'pct_chg_stk' in df.columns:\n",
    "        df['stk_ret_mean_20'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['stk_ret_mean_30'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(30, min_periods=18).mean())\n",
    "        if 'stk_ret_mean_3' in df.columns and 'stk_ret_mean_20' in df.columns:\n",
    "            df['dev_stk_short3_long20'] = df['stk_ret_mean_3'] - df['stk_ret_mean_20']\n",
    "        if 'stk_ret_mean_5' in df.columns and 'stk_ret_mean_30' in df.columns:\n",
    "            df['dev_stk_short5_long30'] = df['stk_ret_mean_5'] - df['stk_ret_mean_30']\n",
    "\n",
    "\n",
    "    # === XII. Risk & Drawdown (CB) ===\n",
    "    print(\"Calculating: XII. Risk & Drawdown (CB)\")\n",
    "    df['cb_low_5'] = df.groupby('code')['close'].transform(lambda x: x.rolling(5, min_periods=3).min())\n",
    "    df['cb_dev_from_low_5'] = safe_division(df['close'] - df['cb_low_5'], df['cb_low_5'])\n",
    "    df['cb_close_std_5'] = df.groupby('code')['close'].transform(lambda x: x.rolling(5, min_periods=3).std())\n",
    "    df['cb_high_5'] = df.groupby('code')['close'].transform(lambda x: x.rolling(5, min_periods=3).max())\n",
    "    df['cb_drawdown_5'] = safe_division(df['close'] - df['cb_high_5'], df['cb_high_5'])\n",
    "    # cb_dd_prob_estimate moved to XV where its components are calculated\n",
    "\n",
    "\n",
    "    # === XIII. Consolidation (CB) ===\n",
    "    print(\"Calculating: XIII. Consolidation (CB)\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'close', 'open', 'pre_close']):\n",
    "        df['range_hl'] = df['high'] - df['low']\n",
    "        df['atr_5'] = df.groupby('code')['range_hl'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "        df['atr_10'] = df.groupby('code')['range_hl'].transform(lambda x: x.rolling(10, min_periods=6).mean())\n",
    "        df['atr_20'] = df.groupby('code')['range_hl'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['atr_decay_5_10'] = safe_division(df['atr_5'], df['atr_10'])\n",
    "        df['atr_decay_5_20'] = safe_division(df['atr_5'], df['atr_20'])\n",
    "\n",
    "        df['close_std_10'] = df.groupby('code')['close'].transform(lambda x: x.rolling(10, min_periods=6).std())\n",
    "        if 'cb_close_std_5' in df.columns: # Dependency check\n",
    "             df['vol_shrink_ratio'] = safe_division(df['cb_close_std_5'], df['close_std_10'])\n",
    "\n",
    "        df['body_abs'] = (df['close'] - df['open']).abs()\n",
    "        df['body_pct'] = safe_division(df['body_abs'], df['pre_close'])\n",
    "        df['body_pct_mean_5'] = df.groupby('code')['body_pct'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "        df['shadow'] = df['range_hl'] - df['body_abs']\n",
    "        df['shadow_ratio'] = safe_division(df['shadow'], df['pre_close'])\n",
    "        df['shadow_mean_5'] = df.groupby('code')['shadow_ratio'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "        df['small_body_shadow_ratio'] = safe_division(df['shadow'], df['body_abs'], default=100)\n",
    "\n",
    "        df['is_doji'] = safe_division(df['body_abs'], df['range_hl']) < 0.15\n",
    "        df['doji_ratio_5'] = df.groupby('code')['is_doji'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "\n",
    "\n",
    "    # === XIV. Impulse & Momentum (CB) ===\n",
    "    print(\"Calculating: XIV. Impulse & Momentum (CB)\")\n",
    "    print(\"  - Skipping: score_high_jump_* (score based)\")\n",
    "    if all(c in df.columns for c in ['high', 'pre_close', 'pct_chg']):\n",
    "        thresholds = [0.015, 0.02, 0.03, 0.04, 0.05, 0.06]\n",
    "        windows = [20, 120, 250, 500]\n",
    "        grouped_pct_chg = df.groupby('code')['pct_chg'] # Pre-group for efficiency\n",
    "\n",
    "        for thres in thresholds:\n",
    "            thres_name = int(thres*1000)\n",
    "            df[f'high_jump_{thres_name}_flag'] = (safe_division(df['high'], df['pre_close']) - 1) > thres\n",
    "            grouped_flag = df.groupby('code')[f'high_jump_{thres_name}_flag']\n",
    "\n",
    "            for win in windows:\n",
    "                print(f\"  - Calculating high_jump stats for thres={thres}, win={win}...\")\n",
    "                # Use helper function via transform if possible, otherwise apply\n",
    "                # Count is easy with transform\n",
    "                df[f'hj_count_{thres_name}_{win}'] = grouped_flag.transform(lambda x: x.rolling(win, min_periods=max(1, int(win*0.6))).sum().fillna(0))\n",
    "\n",
    "                # Mean and Std require apply because they condition on the flag\n",
    "                def calc_hj_mean_std(group):\n",
    "                    flag = group[f'high_jump_{thres_name}_flag']\n",
    "                    pct = group['pct_chg']\n",
    "                    _, mean_s, std_s = rolling_high_jump_stats(flag, pct, win)\n",
    "                    return pd.DataFrame({f'hj_mean_{thres_name}_{win}': mean_s, f'hj_std_{thres_name}_{win}': std_s})\n",
    "\n",
    "                # Apply and join back - ensure index is handled correctly\n",
    "                stats_df = df.groupby('code', group_keys=False).apply(calc_hj_mean_std)\n",
    "                df = df.join(stats_df) # Join based on index (which includes code, trade_date after reset)\n",
    "\n",
    "\n",
    "    if 'open_jump' in df.columns:\n",
    "        for n in [5, 10]:\n",
    "            df[f'open_gap_mean_{n}'] = df.groupby('code')['open_jump'].transform(lambda x: x.rolling(n, min_periods=int(n*0.6)).mean())\n",
    "            df[f'open_gap_max_{n}'] = df.groupby('code')['open_jump'].transform(lambda x: x.rolling(n, min_periods=int(n*0.6)).max())\n",
    "\n",
    "    if 'high' in df.columns and 'close' in df.columns:\n",
    "        for n in [3, 5, 10]:\n",
    "            close_mean_n = df.groupby('code')['close'].transform(lambda x: x.rolling(n, min_periods=max(1,int(n*0.6))).mean())\n",
    "            close_std_n = df.groupby('code')['close'].transform(lambda x: x.rolling(n, min_periods=max(1,int(n*0.6))).std())\n",
    "            df[f'jump_atr_{n}'] = safe_division(df['high'] - close_mean_n, close_std_n)\n",
    "\n",
    "    if 'pct_chg' in df.columns:\n",
    "        pct_mean_20 = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        pct_std_20 = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(20, min_periods=12).std())\n",
    "        df['zscore_pctchg_20'] = safe_division(df['pct_chg'] - pct_mean_20, pct_std_20)\n",
    "\n",
    "    if 'vol' in df.columns:\n",
    "        df['vol_ma20'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['vol_spike_ratio'] = safe_division(df['vol'], df['vol_ma20'], default=1.0)\n",
    "        df['vol_std_5'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(5, min_periods=3).std())\n",
    "        df['vol_std_20'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(20, min_periods=12).std())\n",
    "        df['vol_std_decay'] = safe_division(df['vol_std_5'], df['vol_std_20'])\n",
    "\n",
    "    if 'range_hl' in df.columns and 'atr_5' in df.columns:\n",
    "        df['range_today'] = df['range_hl']\n",
    "        df['range_atr_5'] = safe_division(df['range_today'], df['atr_5'])\n",
    "        df['range_jump_potential'] = (df['range_atr_5'] > 1.5).astype(int)\n",
    "\n",
    "    if all(c in df.columns for c in ['open', 'pre_close', 'close']):\n",
    "        df['gap_and_go_flag'] = ((safe_division(df['open'], df['pre_close']) - 1 > 0.01) & (df['close'] > df['open'])).astype(int)\n",
    "\n",
    "\n",
    "    # === XV. Downside Resilience (CB) ===\n",
    "    print(\"Calculating: XV. Downside Resilience (CB)\")\n",
    "    print(\"  - Skipping: no_fall_score_* (score based)\")\n",
    "    if 'pct_chg' in df.columns:\n",
    "        windows = [20, 60, 120, 250]\n",
    "        grouped_pct_chg = df.groupby('code')['pct_chg'] # Pre-group\n",
    "\n",
    "        for win in windows:\n",
    "            print(f\"  - Calculating downside stats for win={win}...\")\n",
    "\n",
    "            def calc_downside(group):\n",
    "                 pct = group['pct_chg']\n",
    "                 freq_s, mean_s, std_s = rolling_downside_stats(pct, win)\n",
    "                 return pd.DataFrame({\n",
    "                     f'down_freq_{win}': freq_s,\n",
    "                     f'down_amp_mean_{win}': mean_s,\n",
    "                     f'down_amp_std_{win}': std_s\n",
    "                 })\n",
    "\n",
    "            stats_df = df.groupby('code', group_keys=False).apply(calc_downside)\n",
    "            df = df.join(stats_df) # Join based on index\n",
    "\n",
    "        # Original cb_dd_prob_estimate (10d lag1 based)\n",
    "        df['cb_ret_lag1'] = df.groupby('code')['pct_chg'].shift(1)\n",
    "        if 'cb_ret_lag1' in df.columns:\n",
    "            df['cb_fall_flag'] = (df['cb_ret_lag1'] < 0).astype(int)\n",
    "            df['cb_fall_freq_10'] = df.groupby('code')['cb_fall_flag'].transform(lambda x: x.rolling(10, min_periods=6).mean())\n",
    "            df['cb_fall_amp_10'] = df.groupby('code')['cb_ret_lag1'].transform(\n",
    "                lambda x: x.rolling(10, min_periods=6).apply(lambda s: s[s < 0].mean() if (s < 0).any() else 0, raw=True)\n",
    "            )\n",
    "            df['cb_dd_prob_estimate'] = df['cb_fall_freq_10'] * df['cb_fall_amp_10']\n",
    "\n",
    "\n",
    "    # === XVI. K-Line Structure Continuity ===\n",
    "    print(\"Calculating: XVI. K-Line Structure Continuity\")\n",
    "    if all(c in df.columns for c in ['close', 'open']):\n",
    "        df['kline_direction'] = np.sign(df['close'] - df['open'])\n",
    "        df['kline_direction_shift1'] = df.groupby('code')['kline_direction'].shift(1)\n",
    "        if 'kline_direction_shift1' in df.columns: # Check dependency\n",
    "            df['kline_flip'] = (df['kline_direction'] * df['kline_direction_shift1'] < 0).astype(int)\n",
    "            df['kline_flip_ratio_5'] = df.groupby('code')['kline_flip'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "\n",
    "\n",
    "    # --- Final Cleanup & Optional Index Restore ---\n",
    "    # Drop temporary columns if any (like _high_jump_flag_temp)\n",
    "    temp_cols = [col for col in df.columns if col.startswith('_') and col.endswith('_temp')]\n",
    "    df = df.drop(columns=temp_cols, errors='ignore')\n",
    "\n",
    "    if restore_multiindex:\n",
    "        print(\"Restoring MultiIndex ['code', 'trade_date']...\")\n",
    "        df = df.set_index(['code', 'trade_date'])\n",
    "\n",
    "    print(\"Factor calculation finished.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "def safe_division(numerator, denominator, default=np.nan):\n",
    "    \"\"\"Performs division, returning default value if denominator is zero, NaN, or invalid.\"\"\"\n",
    "    try:\n",
    "        # Ensure inputs are numeric if they are series/arrays\n",
    "        if hasattr(numerator, '__iter__'):\n",
    "            numerator = pd.to_numeric(numerator, errors='coerce')\n",
    "        if hasattr(denominator, '__iter__'):\n",
    "            denominator = pd.to_numeric(denominator, errors='coerce')\n",
    "            denominator = denominator.replace(0, np.nan)\n",
    "        elif isinstance(denominator, (int, float)) and denominator == 0:\n",
    "            denominator = np.nan\n",
    "\n",
    "        result = numerator / denominator\n",
    "        if hasattr(result, '__iter__'):\n",
    "             # Replace inf/-inf that might result from large numbers / small numbers\n",
    "             result = result.replace([np.inf, -np.inf], np.nan)\n",
    "             return result.fillna(default)\n",
    "        elif np.isinf(result) or np.isnan(result):\n",
    "             return default\n",
    "        else:\n",
    "             return result\n",
    "\n",
    "    except (TypeError, ValueError):\n",
    "        # Handle cases where inputs cannot be converted to numeric\n",
    "        if hasattr(numerator, 'shape'):\n",
    "             return pd.Series(default, index=getattr(numerator, 'index', None), dtype=float)\n",
    "        elif hasattr(denominator, 'shape'):\n",
    "             return pd.Series(default, index=getattr(denominator, 'index', None), dtype=float)\n",
    "        else:\n",
    "             return default\n",
    "\n",
    "def ts_rank(series, window):\n",
    "    \"\"\"Calculates the rank of the last value in a rolling window.\"\"\"\n",
    "    if series.isnull().all(): # Handle all NaN window\n",
    "        return np.nan\n",
    "    # Rank within the window, get rank of the last element (-1 index)\n",
    "    # pct=True gives rank from 0 to 1\n",
    "    return series.rank(pct=True).iloc[-1]\n",
    "\n",
    "# Rolling correlation helper\n",
    "def rolling_corr(x_series, y_series, window, min_periods):\n",
    "    \"\"\"Safely compute rolling correlation\"\"\"\n",
    "    return x_series.rolling(window=window, min_periods=min_periods).corr(y_series)\n",
    "\n",
    "# Rolling covariance helper\n",
    "def rolling_cov(x_series, y_series, window, min_periods):\n",
    "    \"\"\"Safely compute rolling covariance\"\"\"\n",
    "    return x_series.rolling(window=window, min_periods=min_periods).cov(y_series)\n",
    "\n",
    "# Rolling rank helper (needed for Alpha 65, 99 inner rank)\n",
    "def rolling_series_rank(series, window, min_periods):\n",
    "     # Note: This ranks *within* the rolling window, might not be the same as daily rank\n",
    "     # For Alpha 65/99, the rank is applied *before* rolling.\n",
    "     # This helper is more for concept, usually rank is cross-sectional first.\n",
    "     # We will apply rank cross-sectionally before rolling for alpha factors.\n",
    "     # Keeping this placeholder in case needed for other rolling rank concepts.\n",
    "     # return series.rolling(window=window, min_periods=min_periods).apply(lambda x: x.rank().iloc[-1], raw=False)\n",
    "     pass # Not directly used for the current Alphas as rank is cross-sectional\n",
    "\n",
    "# Assume 'natr' function uses TA-Lib's NATR if not provided externally\n",
    "def apply_natr(group, n):\n",
    "     \"\"\"Applies TA-Lib NATR safely within a group.\"\"\"\n",
    "     if group[['high', 'low', 'close']].isnull().all().all() or len(group) < n:\n",
    "         return pd.Series(np.nan, index=group.index)\n",
    "     # Ensure float type for TA-Lib\n",
    "     high = group['high'].astype(float)\n",
    "     low = group['low'].astype(float)\n",
    "     close = group['close'].astype(float)\n",
    "     return ta.NATR(high, low, close, timeperiod=n)\n",
    "\n",
    "# --- Main Factor Calculation Function ---\n",
    "def calculate_factors(df, restore_multiindex=False):\n",
    "    \"\"\"\n",
    "    计算可转债及其对应正股的衍生因子 (包含基于排名的Alpha因子)。\n",
    "    Handles DataFrame with 'code' and 'trade_date' as columns OR MultiIndex levels.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 输入DataFrame.\n",
    "        restore_multiindex (bool): 若为True, 在末尾将 ['code', 'trade_date'] 设回索引.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 添加了因子列的DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"开始因子计算...\")\n",
    "\n",
    "    # --- 输入验证和索引处理 ---\n",
    "    original_index = df.index # Store original index if needed\n",
    "    if isinstance(df.index, pd.MultiIndex) and all(name in df.index.names for name in ['code', 'trade_date']):\n",
    "        print(\"检测到 'code' 和 'trade_date' 在 MultiIndex 中，正在重置索引...\")\n",
    "        df = df.reset_index()\n",
    "        is_multiindex_input = True\n",
    "    elif all(col in df.columns for col in ['code', 'trade_date']):\n",
    "        print(\"检测到 'code' 和 'trade_date' 在列中。\")\n",
    "        is_multiindex_input = False\n",
    "    else:\n",
    "        raise ValueError(\"DataFrame 必须包含 'code' 和 'trade_date'，可以是在列中或作为 MultiIndex 的层级。\")\n",
    "\n",
    "    # 确保排序\n",
    "    df = df.sort_values(by=['code', 'trade_date']).copy()\n",
    "    # --- 结束索引处理 ---\n",
    "\n",
    "\n",
    "    # 0. 数据类型准备与安全检查\n",
    "    print(\"步骤 0: 准备数据类型...\")\n",
    "    numeric_cols = ['high', 'low', 'close', 'open', 'vol', 'pre_close', 'pct_chg', 'turnover', 'remain_cap', 'float_share',\n",
    "                    'high_stk', 'low_stk', 'close_stk', 'open_stk', 'vol_stk', 'pct_chg_stk']\n",
    "    for col in numeric_cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            df[col] = df[col].replace([np.inf, -np.inf], np.nan)\n",
    "        # else:\n",
    "            # print(f\"  警告: 列 '{col}' 不存在.\")\n",
    "\n",
    "\n",
    "    # === I. 基本价格与波动类因子（转债本身） ===\n",
    "    print(\"计算: I. 基本价格与波动类因子（转债本身）\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'close']):\n",
    "        # NATR\n",
    "        print(\"  - 计算 NATR...\")\n",
    "        df['natr_14'] = df.groupby('code', group_keys=False).apply(apply_natr, n=14)\n",
    "        for n in [1, 3, 5, 10, 20]:\n",
    "            df[f'natr_{n}'] = df.groupby('code', group_keys=False).apply(apply_natr, n=n)\n",
    "\n",
    "        # 振幅\n",
    "        df['zhengfu'] = safe_division(df['high'] - df['low'], df['close'])\n",
    "        if 'open' in df.columns:\n",
    "             df['zhengfu_cha'] = safe_division(df['high'] - df['close'], (df['open'] - df['close']).abs())\n",
    "\n",
    "    if 'close' in df.columns:\n",
    "        # MA, Momentum, Volatility\n",
    "        print(\"  - 计算 MA, Momentum, Volatility...\")\n",
    "        df['ma_20'] = df.groupby('code')['close'].transform(lambda x: ta.SMA(x.astype(float), timeperiod=20))\n",
    "        df['momentum_20'] = df.groupby('code')['close'].transform(lambda x: safe_division(x, x.shift(20)))\n",
    "        df['volatility_20'] = df.groupby('code')['close'].transform(lambda x: x.rolling(20, min_periods=10).std())\n",
    "        # Max Value\n",
    "        df['max_value'] = df.groupby('code')['close'].transform(lambda x: x.cummax().shift(1))\n",
    "        df['max_value_position'] = safe_division(df['close'], df['max_value'])\n",
    "\n",
    "    # 次日止盈特征 (标签)\n",
    "    if 'high' in df.columns and 'close' in df.columns:\n",
    "        print(\"  - 计算次日止盈特征...\")\n",
    "        df['aft_high1'] = df.groupby('code')['high'].shift(-1)\n",
    "        df['aft_high_cur_close'] = safe_division(df['aft_high1'] - df['close'], df['close'])\n",
    "\n",
    "\n",
    "    # === II. OBV量能指标（转债） ===\n",
    "    print(\"计算: II. OBV量能指标（转债）\")\n",
    "    if all(c in df.columns for c in ['close', 'vol']):\n",
    "        df['obv'] = df.groupby('code').apply(\n",
    "             lambda x: ta.OBV(x['close'].astype(float), x['vol'].astype(float)) if not x[['close','vol']].isnull().all().all() else pd.Series(index=x.index, dtype=float)\n",
    "        ).reset_index(level=0, drop=True) # Retain reset_index as used in original for apply\n",
    "        if 'obv' in df.columns:\n",
    "             df['obv_5'] = df.groupby('code')['obv'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "             df['obv_10'] = df.groupby('code')['obv'].transform(lambda x: x.rolling(10, min_periods=5).mean())\n",
    "             df['obv_ratio_5_10'] = safe_division(df['obv_5'], df['obv_10'])\n",
    "\n",
    "\n",
    "    # === III. 换手与市值类因子 ===\n",
    "    print(\"计算: III. 换手与市值类因子\")\n",
    "    if 'turnover' in df.columns:\n",
    "        print(\"  - 计算 turnover 相关因子...\")\n",
    "        # Calculate turnover_pct as intermediate step (needed for rolling_avg)\n",
    "        df['turnover_pct_temp'] = df.groupby('trade_date')['turnover'].rank(pct=True)\n",
    "        # 均值换手率\n",
    "        for win in [5, 10, 20, 60]:\n",
    "            df[f'turnover_{win}_avg'] = df.groupby('code')['turnover'].transform(lambda x: x.rolling(window=win, min_periods=int(win*0.6)).mean())\n",
    "        # 分位换手率均值 (依赖 turnover_pct_temp)\n",
    "        if 'turnover_pct_temp' in df.columns:\n",
    "            for win in [1, 5, 20, 50]:\n",
    "                 df[f'rolling_{win}_avg'] = df.groupby('code')['turnover_pct_temp'].transform(lambda x: x.rolling(window=win, min_periods=max(1,int(win*0.6))).mean())\n",
    "            # 分位换手率比率\n",
    "            if all(c in df.columns for c in ['rolling_1_avg', 'rolling_5_avg', 'rolling_20_avg', 'rolling_50_avg']):\n",
    "                 df['rolling_1_to_5_avg'] = safe_division(df['rolling_1_avg'], df['rolling_5_avg'])\n",
    "                 df['rolling_5_to_20_avg'] = safe_division(df['rolling_5_avg'], df['rolling_20_avg'])\n",
    "                 df['rolling_20_to_50_avg'] = safe_division(df['rolling_20_avg'], df['rolling_50_avg'])\n",
    "            # Drop intermediate temp column\n",
    "            df = df.drop(columns=['turnover_pct_temp'])\n",
    "        else:\n",
    "            print(\"  警告: 无法计算 rolling_avg 等因子，因为 turnover_pct_temp 未成功计算。\")\n",
    "\n",
    "    if all(col in df.columns for col in ['remain_cap', 'float_share', 'close_stk']):\n",
    "        print(\"  - 计算 cap_float_share_rate...\")\n",
    "        df['cap_float_share_rate'] = safe_division(df['remain_cap'] * 10000, (df['float_share'] * df['close_stk']))\n",
    "\n",
    "\n",
    "    # === IV. 区间收益率（转债与股票） ===\n",
    "    print(\"计算: IV. 区间收益率（转债与股票）\")\n",
    "    # Use mean return naming consistently for deviation factors later\n",
    "    windows_ret = [3, 5, 10, 20]\n",
    "    if 'pct_chg' in df.columns:\n",
    "        print(\"  - 计算转债区间收益率...\")\n",
    "        for win in windows_ret:\n",
    "            # Cumulative Product Return\n",
    "            df[f'pct_chg_{win}'] = df.groupby('code')['pct_chg'].transform(\n",
    "                lambda x: (x + 1).rolling(win, min_periods=max(1,int(win*0.6))).apply(np.prod, raw=True) - 1\n",
    "            )\n",
    "            # Mean Arithmetic Return\n",
    "            df[f'bond_ret_mean_{win}'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(win, min_periods=max(1,int(win*0.6))).mean())\n",
    "\n",
    "    if 'pct_chg_stk' in df.columns:\n",
    "        print(\"  - 计算股票区间收益率...\")\n",
    "        for win in windows_ret:\n",
    "            df[f'pct_chg_stk_{win}'] = df.groupby('code')['pct_chg_stk'].transform(\n",
    "                lambda x: (x + 1).rolling(win, min_periods=max(1,int(win*0.6))).apply(np.prod, raw=True) - 1\n",
    "            )\n",
    "            df[f'stk_ret_mean_{win}'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(win, min_periods=max(1,int(win*0.6))).mean())\n",
    "\n",
    "\n",
    "    # === V. 成交量均值比因子（转债） ===\n",
    "    print(\"计算: V. 成交量均值比因子（转债）\")\n",
    "    if 'vol' in df.columns:\n",
    "        vol_windows = [3, 5, 10, 20, 30, 60]\n",
    "        print(\"  - 计算均量...\")\n",
    "        for n in vol_windows:\n",
    "            df[f'vol_{n}_avg'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(n, min_periods=int(n*0.6)).mean())\n",
    "        print(\"  - 计算量比...\")\n",
    "        for n in vol_windows:\n",
    "            for m in vol_windows:\n",
    "                if n < m and f'vol_{n}_avg' in df.columns and f'vol_{m}_avg' in df.columns:\n",
    "                    df[f'vol_{n}_to_{m}'] = safe_division(df[f'vol_{n}_avg'], df[f'vol_{m}_avg'])\n",
    "\n",
    "\n",
    "    # === VI. 波动率与振幅（转债与股票） ===\n",
    "    print(\"计算: VI. 波动率与振幅（转债与股票）\")\n",
    "    bodong_windows = [5, 10, 20, 60]\n",
    "    if 'pct_chg_stk' in df.columns:\n",
    "        print(\"  - 计算股票波动率...\")\n",
    "        for win in bodong_windows:\n",
    "            df[f'bodong_{win}'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(win, min_periods=int(win*0.6)).std() * (win ** 0.5))\n",
    "        if all(c in df.columns for c in ['bodong_20', 'bodong_60']):\n",
    "            df['bodong_20_to_bodong_60'] = safe_division(df['bodong_20'], df['bodong_60'])\n",
    "\n",
    "    if 'pct_chg' in df.columns:\n",
    "        print(\"  - 计算转债波动率...\")\n",
    "        for win in bodong_windows:\n",
    "             df[f'bodong_{win}_bd'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(win, min_periods=int(win*0.6)).std() * (win ** 0.5))\n",
    "\n",
    "    if 'zhengfu' in df.columns:\n",
    "        print(\"  - 计算振幅波动...\")\n",
    "        for win in [1, 5, 10, 20, 60]:\n",
    "            df[f'zhengfu_{win}'] = df.groupby('code')['zhengfu'].transform(lambda x: x.rolling(win, min_periods=max(1,int(win*0.6))).std())\n",
    "            df[f'zhengfu_{win}_bodong'] = df[f'zhengfu_{win}'] * (win ** 0.5)\n",
    "\n",
    "\n",
    "    # === VII. 跳空与缺口类因子（转债） ===\n",
    "    print(\"计算: VII. 跳空与缺口类因子（转债）\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'open', 'close', 'pre_close']):\n",
    "        print(\"  - 计算基础跳空/缺口指标...\")\n",
    "        df['high_jump'] = (safe_division(df['high'], df['pre_close']) - 1) > 0.025 # Used in count\n",
    "        df['low_gap'] = (safe_division(df['low'], df['pre_close']) - 1) < -0.025   # Used in count\n",
    "        df['open_jump'] = (safe_division(df['open'], df['pre_close']) - 1).abs()\n",
    "        df['gap_body_ratio'] = safe_division(df['open'] - df['pre_close'], (df['close'] - df['open']))\n",
    "\n",
    "        jump_windows = [20, 100, 250] # Windows from original code\n",
    "        print(\"  - 计算跳空/缺口统计...\")\n",
    "        if 'high_jump' in df.columns:\n",
    "            for win in jump_windows:\n",
    "                 df[f'high_jump_count_{win}'] = df.groupby('code')['high_jump'].transform(lambda x: x.rolling(window=win, min_periods=int(win*0.6)).sum())\n",
    "                 # Calculate pct rank based on count\n",
    "                 df[f'high_jump_count_{win}_pct'] = df.groupby('trade_date')[f'high_jump_count_{win}'].rank(pct=True)\n",
    "        if 'low_gap' in df.columns:\n",
    "            for win in jump_windows:\n",
    "                 df[f'low_gap_count_{win}'] = df.groupby('code')['low_gap'].transform(lambda x: x.rolling(window=win, min_periods=int(win*0.6)).sum())\n",
    "                 df[f'low_gap_count_{win}_pct'] = df.groupby('trade_date')[f'low_gap_count_{win}'].rank(pct=True)\n",
    "\n",
    "\n",
    "    # === VIII. K线结构因子（转债） ===\n",
    "    print(\"计算: VIII. K线结构因子（转债）\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'open', 'close']):\n",
    "        high_low_diff = safe_division(1.0, df['high'] - df['low']) # Precompute inverse for safety/efficiency\n",
    "        df['close_to_high_ratio'] = (df['close'] - df['low']) * high_low_diff\n",
    "        df['close_to_low_ratio'] = (df['high'] - df['close']) * high_low_diff\n",
    "        df['body_position'] = (df['close'] - df['open']) * high_low_diff\n",
    "        df['upper_shadow_ratio'] = (df['high'] - df[['close', 'open']].max(axis=1)) * high_low_diff\n",
    "        df['lower_shadow_ratio'] = (df[['close', 'open']].min(axis=1) - df['low']) * high_low_diff\n",
    "\n",
    "\n",
    "    # === IX. 趋势反转类Alpha因子（转债与股票） ===\n",
    "    print(\"计算: IX. 趋势反转类Alpha因子（转债与股票）\")\n",
    "    # --- Prerequisites ---\n",
    "    print(\"  - 计算 Alpha 因子前置数据...\")\n",
    "    df['delta_close_1'] = df.groupby('code')['close'].transform(lambda x: x.diff(1))\n",
    "    df['delta_vol_1'] = df.groupby('code')['vol'].transform(lambda x: x.diff(1))\n",
    "    df['delta_close_5'] = df.groupby('code')['close'].transform(lambda x: x.diff(5))\n",
    "    df['delta_close_10'] = df.groupby('code')['close'].transform(lambda x: x.diff(10))\n",
    "    df['mean_close_20'] = df.groupby('code')['close'].transform(lambda x: x.rolling(20, min_periods=10).mean())\n",
    "\n",
    "    if 'close_stk' in df.columns:\n",
    "        df['delta_close_1_stk'] = df.groupby('code')['close_stk'].transform(lambda x: x.diff(1))\n",
    "        df['delta_close_5_stk'] = df.groupby('code')['close_stk'].transform(lambda x: x.diff(5))\n",
    "        df['delta_close_10_stk'] = df.groupby('code')['close_stk'].transform(lambda x: x.diff(10))\n",
    "        df['mean_close_20_stk'] = df.groupby('code')['close_stk'].transform(lambda x: x.rolling(20, min_periods=10).mean())\n",
    "    if 'vol_stk' in df.columns:\n",
    "        df['delta_vol_1_stk'] = df.groupby('code')['vol_stk'].transform(lambda x: x.diff(1))\n",
    "\n",
    "    # --- Cross-sectional Ranks (can be slow) ---\n",
    "    print(\"  - 计算截面排名 (可能较慢)...\")\n",
    "    if 'delta_close_10' in df.columns:\n",
    "        df['rank_delta_close_10'] = df.groupby('trade_date')['delta_close_10'].rank()\n",
    "    if 'vol' in df.columns:\n",
    "        df['rank_vol'] = df.groupby('trade_date')['vol'].rank()\n",
    "    if 'mean_close_20' in df.columns:\n",
    "        df['rank_mean_close_20'] = df.groupby('trade_date')['mean_close_20'].rank()\n",
    "    if 'close' in df.columns: # Rank close needed for Alpha65, 99\n",
    "         df['rank_close'] = df.groupby('trade_date')['close'].rank()\n",
    "\n",
    "    if 'delta_close_10_stk' in df.columns:\n",
    "        df['rank_delta_close_10_stk'] = df.groupby('trade_date')['delta_close_10_stk'].rank()\n",
    "    if 'vol_stk' in df.columns:\n",
    "        df['rank_vol_stk'] = df.groupby('trade_date')['vol_stk'].rank()\n",
    "    if 'mean_close_20_stk' in df.columns:\n",
    "        df['rank_mean_close_20_stk'] = df.groupby('trade_date')['mean_close_20_stk'].rank()\n",
    "    if 'close_stk' in df.columns: # Rank close_stk needed for Alpha65_stk, 99_stk\n",
    "         df['rank_close_stk'] = df.groupby('trade_date')['close_stk'].rank()\n",
    "\n",
    "    # --- Alpha Calculations ---\n",
    "    # Alpha6: -corr(rank(delta(close, 10)), rank(vol), 10)\n",
    "    print(\"  - 计算 Alpha6...\")\n",
    "    if all(c in df.columns for c in ['rank_delta_close_10', 'rank_vol']):\n",
    "         df['alpha6'] = df.groupby('code').apply(\n",
    "             lambda x: rolling_corr(x['rank_delta_close_10'], x['rank_vol'], 10, 6) * -1\n",
    "         ).reset_index(level=0, drop=True)\n",
    "    if all(c in df.columns for c in ['rank_delta_close_10_stk', 'rank_vol_stk']):\n",
    "         df['alpha6_stk'] = df.groupby('code').apply(\n",
    "             lambda x: rolling_corr(x['rank_delta_close_10_stk'], x['rank_vol_stk'], 10, 6) * -1\n",
    "         ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Alpha12: sign(delta(vol, 1)) * -1 * delta(close, 1)\n",
    "    print(\"  - 计算 Alpha12...\")\n",
    "    if all(c in df.columns for c in ['delta_vol_1', 'delta_close_1']):\n",
    "        df['alpha12'] = np.sign(df['delta_vol_1']) * -1 * df['delta_close_1']\n",
    "    if all(c in df.columns for c in ['delta_vol_1_stk', 'delta_close_1_stk']):\n",
    "        df['alpha12_stk'] = np.sign(df['delta_vol_1_stk']) * -1 * df['delta_close_1_stk']\n",
    "\n",
    "    # Alpha83: Days since 30d high (Corrected)\n",
    "    print(\"  - 计算 Alpha83...\")\n",
    "    df['alpha83'] = df.groupby('code')['close'].transform(\n",
    "        lambda x: x.rolling(30, min_periods=15).apply(\n",
    "            lambda s: (len(s) - 1) - np.nanargmax(s.to_numpy()) if not s.isnull().all() else np.nan, raw=False\n",
    "        )\n",
    "    )\n",
    "    if 'close_stk' in df.columns:\n",
    "        df['alpha83_stk'] = df.groupby('code')['close_stk'].transform(\n",
    "            lambda x: x.rolling(30, min_periods=15).apply(\n",
    "                lambda s: (len(s) - 1) - np.nanargmax(s.to_numpy()) if not s.isnull().all() else np.nan, raw=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Alpha18: close / rank(mean(close, 20))\n",
    "    print(\"  - 计算 Alpha18...\")\n",
    "    if all(c in df.columns for c in ['close', 'rank_mean_close_20']):\n",
    "        df['alpha18'] = safe_division(df['close'], df['rank_mean_close_20'])\n",
    "    if all(c in df.columns for c in ['close_stk', 'rank_mean_close_20_stk']):\n",
    "        df['alpha18_stk'] = safe_division(df['close_stk'], df['rank_mean_close_20_stk'])\n",
    "\n",
    "    # Alpha36: (correlation(vol, close, 5)) + (correlation(vol, open, 5))\n",
    "    print(\"  - 计算 Alpha36...\")\n",
    "    if all(c in df.columns for c in ['vol', 'close', 'open']):\n",
    "        def calc_alpha36(x):\n",
    "             corr_close = rolling_corr(x['vol'], x['close'], 5, 3)\n",
    "             corr_open = rolling_corr(x['vol'], x['open'], 5, 3)\n",
    "             return corr_close.add(corr_open, fill_value=0) # Handle potential NaNs\n",
    "        df['alpha36'] = df.groupby('code', group_keys=False).apply(calc_alpha36)\n",
    "    if all(c in df.columns for c in ['vol_stk', 'close_stk', 'open_stk']):\n",
    "        def calc_alpha36_stk(x):\n",
    "             corr_close = rolling_corr(x['vol_stk'], x['close_stk'], 5, 3)\n",
    "             corr_open = rolling_corr(x['vol_stk'], x['open_stk'], 5, 3)\n",
    "             return corr_close.add(corr_open, fill_value=0)\n",
    "        df['alpha36_stk'] = df.groupby('code', group_keys=False).apply(calc_alpha36_stk)\n",
    "\n",
    "    # Alpha89: (days since high) / (days since low + eps) (Corrected)\n",
    "    print(\"  - 计算 Alpha89...\")\n",
    "    df['argmin_close_30_idx_pos'] = df.groupby('code')['close'].transform(\n",
    "        lambda x: x.rolling(30, min_periods=15).apply(\n",
    "            lambda s: (len(s) - 1) - np.nanargmin(s.to_numpy()) if not s.isnull().all() else np.nan, raw=False\n",
    "        )\n",
    "    )\n",
    "    if 'alpha83' in df.columns: # Check dependencies\n",
    "        df['alpha89'] = safe_division(df['alpha83'], df['argmin_close_30_idx_pos'])\n",
    "    if 'close_stk' in df.columns:\n",
    "        df['argmin_close_30_idx_pos_stk'] = df.groupby('code')['close_stk'].transform(\n",
    "             lambda x: x.rolling(30, min_periods=15).apply(\n",
    "                 lambda s: (len(s) - 1) - np.nanargmin(s.to_numpy()) if not s.isnull().all() else np.nan, raw=False\n",
    "             )\n",
    "        )\n",
    "        if 'alpha83_stk' in df.columns: # Check dependencies\n",
    "            df['alpha89_stk'] = safe_division(df['alpha83_stk'], df['argmin_close_30_idx_pos_stk'])\n",
    "\n",
    "    # Alpha65: correlation(rank(close), rank(vol), 6)\n",
    "    print(\"  - 计算 Alpha65...\")\n",
    "    if all(c in df.columns for c in ['rank_close', 'rank_vol']):\n",
    "         df['alpha65'] = df.groupby('code').apply(\n",
    "             lambda x: rolling_corr(x['rank_close'], x['rank_vol'], 6, 4)\n",
    "         ).reset_index(level=0, drop=True)\n",
    "    if all(c in df.columns for c in ['rank_close_stk', 'rank_vol_stk']):\n",
    "         df['alpha65_stk'] = df.groupby('code').apply(\n",
    "             lambda x: rolling_corr(x['rank_close_stk'], x['rank_vol_stk'], 6, 4)\n",
    "         ).reset_index(level=0, drop=True)\n",
    "\n",
    "    # Alpha76: -1 * ts_rank(correlation(close, vol, 10), 10)\n",
    "    print(\"  - 计算 Alpha76...\")\n",
    "    if all(c in df.columns for c in ['close', 'vol']):\n",
    "        df['corr_close_vol_10'] = df.groupby('code').apply(\n",
    "            lambda x: rolling_corr(x['close'], x['vol'], 10, 6)\n",
    "        ).reset_index(level=0, drop=True)\n",
    "        # Apply ts_rank using rolling apply\n",
    "        df['alpha76'] = df.groupby('code')['corr_close_vol_10'].transform(\n",
    "             lambda x: -1 * x.rolling(10, min_periods=6).apply(ts_rank, raw=False, args=(10,))\n",
    "        )\n",
    "    if all(c in df.columns for c in ['close_stk', 'vol_stk']):\n",
    "        df['corr_close_vol_10_stk'] = df.groupby('code').apply(\n",
    "            lambda x: rolling_corr(x['close_stk'], x['vol_stk'], 10, 6)\n",
    "        ).reset_index(level=0, drop=True)\n",
    "        df['alpha76_stk'] = df.groupby('code')['corr_close_vol_10_stk'].transform(\n",
    "             lambda x: -1 * x.rolling(10, min_periods=6).apply(ts_rank, raw=False, args=(10,))\n",
    "        )\n",
    "\n",
    "    # Alpha92: (delta(close, 5)/close) * vol\n",
    "    print(\"  - 计算 Alpha92...\")\n",
    "    if all(c in df.columns for c in ['delta_close_5', 'close', 'vol']):\n",
    "        df['alpha92'] = safe_division(df['delta_close_5'], df['close']) * df['vol']\n",
    "    if all(c in df.columns for c in ['delta_close_5_stk', 'close_stk', 'vol_stk']):\n",
    "        df['alpha92_stk'] = safe_division(df['delta_close_5_stk'], df['close_stk']) * df['vol_stk']\n",
    "\n",
    "    # Alpha99: -1 * ts_rank(cov(rank(close), rank(vol), 5), 5)\n",
    "    print(\"  - 计算 Alpha99...\")\n",
    "    if all(c in df.columns for c in ['rank_close', 'rank_vol']):\n",
    "         df['cov_rank_close_vol_5'] = df.groupby('code').apply(\n",
    "             lambda x: rolling_cov(x['rank_close'], x['rank_vol'], 5, 3)\n",
    "         ).reset_index(level=0, drop=True)\n",
    "         df['alpha99'] = df.groupby('code')['cov_rank_close_vol_5'].transform(\n",
    "              lambda x: -1 * x.rolling(5, min_periods=3).apply(ts_rank, raw=False, args=(5,))\n",
    "         )\n",
    "    if all(c in df.columns for c in ['rank_close_stk', 'rank_vol_stk']):\n",
    "         df['cov_rank_close_vol_5_stk'] = df.groupby('code').apply(\n",
    "             lambda x: rolling_cov(x['rank_close_stk'], x['rank_vol_stk'], 5, 3)\n",
    "         ).reset_index(level=0, drop=True)\n",
    "         df['alpha99_stk'] = df.groupby('code')['cov_rank_close_vol_5_stk'].transform(\n",
    "              lambda x: -1 * x.rolling(5, min_periods=3).apply(ts_rank, raw=False, args=(5,))\n",
    "         )\n",
    "\n",
    "\n",
    "    # === X. 股票与转债联动因子 ===\n",
    "    print(\"计算: X. 股票与转债联动因子\")\n",
    "    if 'pct_chg' in df.columns and 'pct_chg_stk' in df.columns:\n",
    "        print(\"  - 计算日内联动...\")\n",
    "        df['stk_up_bond_flat'] = ((df['pct_chg_stk'] > 0.03) & (df['pct_chg'] < 0.01)).astype(int)\n",
    "        df['stk_down_bond_weak'] = ((df['pct_chg_stk'] < -0.03) & (df['pct_chg'] < df['pct_chg_stk'])).astype(int)\n",
    "        # Lagged vars\n",
    "        df['pct_chg_stk_lag1'] = df.groupby('code')['pct_chg_stk'].shift(1)\n",
    "        df['pct_chg_stk_lag2'] = df.groupby('code')['pct_chg_stk'].shift(2)\n",
    "        if 'pct_chg_stk_lag1' in df.columns:\n",
    "            df['bond_hold_stk_rebound'] = ((df['pct_chg_stk_lag1'] < -0.03) & (df['pct_chg_stk'] > 0.01) & (df['pct_chg'] > 0.005)).astype(int)\n",
    "        if 'pct_chg_stk_lag2' in df.columns:\n",
    "            df['stk_down_then_up'] = ((df['pct_chg_stk_lag2'] < -0.03) & (df['pct_chg_stk'] > 0.02)).astype(int)\n",
    "        df['bond_rebound'] = (df['pct_chg'] > 0.01).astype(int)\n",
    "        if 'stk_down_then_up' in df.columns: # Check dependency\n",
    "            df['bond_follow_stk_rebound'] = ((df['stk_down_then_up'] == 1) & (df['bond_rebound'] == 1)).astype(int)\n",
    "\n",
    "        print(\"  - 计算多日联动 (滞涨)...\")\n",
    "        # Multi-day linkage (using mean returns calculated in section IV)\n",
    "        # Naming stk_chg_N/bond_chg_N based on original code, points to mean returns\n",
    "        df['stk_chg_3'] = df['stk_ret_mean_3'] if 'stk_ret_mean_3' in df.columns else np.nan\n",
    "        df['bond_chg_3'] = df['bond_ret_mean_3'] if 'bond_ret_mean_3' in df.columns else np.nan\n",
    "        df['stk_chg_5'] = df['stk_ret_mean_5'] if 'stk_ret_mean_5' in df.columns else np.nan\n",
    "        df['bond_chg_5'] = df['bond_ret_mean_5'] if 'bond_ret_mean_5' in df.columns else np.nan\n",
    "\n",
    "        if all(c in df.columns for c in ['stk_chg_3', 'bond_chg_3']):\n",
    "             df['stk_up_bond_flat_3'] = ((df['stk_chg_3'] > 0.03) & (df['bond_chg_3'] < 0.01)).astype(int)\n",
    "        if all(c in df.columns for c in ['stk_chg_5', 'bond_chg_5']):\n",
    "             df['stk_up_bond_flat_5'] = ((df['stk_chg_5'] > 0.05) & (df['bond_chg_5'] < 0.01)).astype(int)\n",
    "\n",
    "\n",
    "    # === XI. 横纵向背离因子（股票与转债） ===\n",
    "    print(\"计算: XI. 横纵向背离因子（股票与转债）\")\n",
    "    print(\"  - 计算横向背离...\")\n",
    "    for win in [3, 5, 10]:\n",
    "        # Deviation using mean returns\n",
    "        if f'bond_ret_mean_{win}' in df.columns and f'stk_ret_mean_{win}' in df.columns:\n",
    "            df[f'dev_bond_vs_stk_{win}'] = df[f'bond_ret_mean_{win}'] - df[f'stk_ret_mean_{win}']\n",
    "        # Rank difference (requires returns calculated in IV)\n",
    "        if f'pct_chg_{win}' in df.columns :\n",
    "             df[f'cb_ret_rank_{win}'] = df.groupby('trade_date')[f'pct_chg_{win}'].rank() # Rank based on cumulative return\n",
    "        if f'pct_chg_stk_{win}' in df.columns:\n",
    "             df[f'stk_ret_rank_{win}'] = df.groupby('trade_date')[f'pct_chg_stk_{win}'].rank()\n",
    "        if f'cb_ret_rank_{win}' in df.columns and f'stk_ret_rank_{win}' in df.columns:\n",
    "             df[f'cb_vs_stk_ret_rank_diff_{win}'] = df[f'cb_ret_rank_{win}'] - df[f'stk_ret_rank_{win}']\n",
    "\n",
    "    print(\"  - 计算纵向背离...\")\n",
    "    # Longer term means needed\n",
    "    if 'pct_chg' in df.columns:\n",
    "        df['bond_ret_mean_20'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['bond_ret_mean_30'] = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(30, min_periods=18).mean())\n",
    "        if 'bond_ret_mean_3' in df.columns and 'bond_ret_mean_20' in df.columns:\n",
    "            df['dev_bond_short3_long20'] = df['bond_ret_mean_3'] - df['bond_ret_mean_20']\n",
    "        if 'bond_ret_mean_5' in df.columns and 'bond_ret_mean_30' in df.columns:\n",
    "            df['dev_bond_short5_long30'] = df['bond_ret_mean_5'] - df['bond_ret_mean_30']\n",
    "\n",
    "    if 'pct_chg_stk' in df.columns:\n",
    "        df['stk_ret_mean_20'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['stk_ret_mean_30'] = df.groupby('code')['pct_chg_stk'].transform(lambda x: x.rolling(30, min_periods=18).mean())\n",
    "        if 'stk_ret_mean_3' in df.columns and 'stk_ret_mean_20' in df.columns:\n",
    "            df['dev_stk_short3_long20'] = df['stk_ret_mean_3'] - df['stk_ret_mean_20']\n",
    "        if 'stk_ret_mean_5' in df.columns and 'stk_ret_mean_30' in df.columns:\n",
    "            df['dev_stk_short5_long30'] = df['stk_ret_mean_5'] - df['stk_ret_mean_30']\n",
    "\n",
    "\n",
    "    # === XII. 风险与回撤相关因子（转债） ===\n",
    "    print(\"计算: XII. 风险与回撤相关因子（转债）\")\n",
    "    if 'close' in df.columns:\n",
    "        print(\"  - 计算低点距离/标准差/回撤...\")\n",
    "        df['cb_low_5'] = df.groupby('code')['close'].transform(lambda x: x.rolling(5, min_periods=3).min())\n",
    "        df['cb_dev_from_low_5'] = safe_division(df['close'] - df['cb_low_5'], df['cb_low_5'])\n",
    "        df['cb_close_std_5'] = df.groupby('code')['close'].transform(lambda x: x.rolling(5, min_periods=3).std())\n",
    "        df['cb_high_5'] = df.groupby('code')['close'].transform(lambda x: x.rolling(5, min_periods=3).max())\n",
    "        df['cb_drawdown_5'] = safe_division(df['close'] - df['cb_high_5'], df['cb_high_5'])\n",
    "\n",
    "    if 'pct_chg' in df.columns:\n",
    "        print(\"  - 计算下跌风险预估...\")\n",
    "        df['cb_ret_1'] = df.groupby('code')['pct_chg'].shift(1) # Renamed from original cb_ret_1\n",
    "        df['cb_fall_flag'] = (df['cb_ret_1'] < 0).astype(int)\n",
    "        df['cb_fall_freq_10'] = df.groupby('code')['cb_fall_flag'].transform(lambda x: x.rolling(10, min_periods=6).mean())\n",
    "        df['cb_fall_amp_10'] = df.groupby('code')['cb_ret_1'].transform(\n",
    "            lambda x: x.rolling(10, min_periods=6).apply(lambda s: s[s < 0].mean() if (s < 0).any() else 0, raw=True)\n",
    "        )\n",
    "        df['cb_dd_prob_estimate'] = df['cb_fall_freq_10'] * df['cb_fall_amp_10']\n",
    "\n",
    "\n",
    "    # === XIII. 震荡收敛类因子（转债） ===\n",
    "    print(\"计算: XIII. 震荡收敛类因子（转债）\")\n",
    "    if all(c in df.columns for c in ['high', 'low', 'close', 'open', 'pre_close']):\n",
    "        print(\"  - 计算 ATR/振幅/价格波动 收敛...\")\n",
    "        df['range_hl'] = df['high'] - df['low'] # Reusable range\n",
    "        df['atr_5'] = df.groupby('code')['range_hl'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "        df['atr_10'] = df.groupby('code')['range_hl'].transform(lambda x: x.rolling(10, min_periods=6).mean()) # Needed in one snippet\n",
    "        df['atr_20'] = df.groupby('code')['range_hl'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['atr_5_decay'] = safe_division(df['atr_5'], df['atr_20']) # Based on snippet\n",
    "        df['atr_decay_5_10'] = safe_division(df['atr_5'], df['atr_10']) # Based on snippet\n",
    "\n",
    "        # Zhengfu decay / Range ratio (similar to atr decay)\n",
    "        # df['zhengfu_5'] = df['atr_5'] # Redundant if atr_5 exists\n",
    "        # df['zhengfu_20'] = df['atr_20']\n",
    "        df['zhengfu_decay_5_20'] = safe_division(df['atr_5'], df['atr_20']) # Reusing ATR calc\n",
    "        df['range_ratio_5_20'] = safe_division(df['atr_5'], df['atr_20']) # Reusing ATR calc\n",
    "\n",
    "        # Close std deviation shrink\n",
    "        df['close_std_10'] = df.groupby('code')['close'].transform(lambda x: x.rolling(10, min_periods=6).std())\n",
    "        if 'cb_close_std_5' in df.columns: # Dependency from Sec XII\n",
    "             df['vol_shrink_ratio'] = safe_division(df['cb_close_std_5'], df['close_std_10'])\n",
    "\n",
    "        print(\"  - 计算 K线实体/影线/十字星 特征...\")\n",
    "        df['body_abs'] = (df['close'] - df['open']).abs()\n",
    "        df['body_pct'] = safe_division(df['body_abs'], df['pre_close'])\n",
    "        df['body_pct_mean_5'] = df.groupby('code')['body_pct'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "\n",
    "        df['shadow'] = df['range_hl'] - df['body_abs']\n",
    "        df['shadow_ratio'] = safe_division(df['shadow'], df['pre_close'])\n",
    "        df['shadow_mean_5'] = df.groupby('code')['shadow_ratio'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "        df['small_body_shadow_ratio'] = safe_division(df['shadow'], df['body_abs'], default=100) # Assign large number if body is zero\n",
    "\n",
    "        df['is_doji'] = safe_division(df['body_abs'], df['range_hl']) < 0.15\n",
    "        df['doji_ratio_5'] = df.groupby('code')['is_doji'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "\n",
    "\n",
    "    # === XIV. 脉冲与动能因子（转债） ===\n",
    "    print(\"计算: XIV. 脉冲与动能因子（转债）\")\n",
    "    if all(c in df.columns for c in ['high', 'pre_close', 'pct_chg', 'vol', 'close', 'low']):\n",
    "        print(\"  - 计算高脉冲统计 (count, mean, score)...\")\n",
    "        thresholds = [0.015, 0.02, 0.03, 0.04, 0.05, 0.06]\n",
    "        pulse_window = 20 # Window used for score in original code\n",
    "        for thres in thresholds:\n",
    "            thres_name = int(thres*1000)\n",
    "            # Flag\n",
    "            df[f'high_jump_{thres_name}'] = (safe_division(df['high'], df['pre_close']) - 1) > thres\n",
    "            # Count (rolling sum of flags)\n",
    "            df[f'count_high_jump_{thres_name}_{pulse_window}'] = df.groupby('code')[f'high_jump_{thres_name}'].transform(\n",
    "                lambda x: x.rolling(pulse_window, min_periods=int(pulse_window*0.6)).sum()\n",
    "            )\n",
    "            # Mean return on jump days\n",
    "            df[f'mean_high_jump_{thres_name}_{pulse_window}'] = df.groupby('code').apply(\n",
    "                 lambda x: x['pct_chg'].where(x[f'high_jump_{thres_name}']).rolling(pulse_window, min_periods=1).mean() # Need at least 1 jump day for mean\n",
    "            ).reset_index(level=0, drop=True)\n",
    "            # Score\n",
    "            if f'count_high_jump_{thres_name}_{pulse_window}' in df.columns and f'mean_high_jump_{thres_name}_{pulse_window}' in df.columns:\n",
    "                 df[f'score_high_jump_{thres_name}_{pulse_window}'] = df[f'count_high_jump_{thres_name}_{pulse_window}'] * df[f'mean_high_jump_{thres_name}_{pulse_window}']\n",
    "\n",
    "        print(\"  - 计算其他脉冲指标...\")\n",
    "        # Z-score\n",
    "        pct_mean_20 = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        pct_std_20 = df.groupby('code')['pct_chg'].transform(lambda x: x.rolling(20, min_periods=12).std())\n",
    "        df['zscore_pctchg_20'] = safe_division(df['pct_chg'] - pct_mean_20, pct_std_20)\n",
    "\n",
    "        # Volume spike & decay\n",
    "        df['vol_ma20'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(20, min_periods=12).mean())\n",
    "        df['vol_spike_ratio'] = safe_division(df['vol'], df['vol_ma20'], default=1.0)\n",
    "        df['vol_std_5'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(5, min_periods=3).std())\n",
    "        df['vol_std_20'] = df.groupby('code')['vol'].transform(lambda x: x.rolling(20, min_periods=12).std())\n",
    "        df['vol_std_decay'] = safe_division(df['vol_std_5'], df['vol_std_20'])\n",
    "\n",
    "        # Open gap stats\n",
    "        if 'open_jump' in df.columns: # Calculated in Sec VII\n",
    "             for n in [5, 10]:\n",
    "                 df[f'open_gap_mean_{n}'] = df.groupby('code')['open_jump'].transform(lambda x: x.rolling(n, min_periods=int(n*0.6)).mean())\n",
    "                 df[f'open_gap_max_{n}'] = df.groupby('code')['open_jump'].transform(lambda x: x.rolling(n, min_periods=int(n*0.6)).max())\n",
    "\n",
    "        # Jump ATR\n",
    "        for n in [3, 5, 10]:\n",
    "            close_mean_n = df.groupby('code')['close'].transform(lambda x: x.rolling(n, min_periods=max(1,int(n*0.6))).mean())\n",
    "            close_std_n = df.groupby('code')['close'].transform(lambda x: x.rolling(n, min_periods=max(1,int(n*0.6))).std())\n",
    "            df[f'jump_atr_{n}'] = safe_division(df['high'] - close_mean_n, close_std_n)\n",
    "\n",
    "        # Range jump potential\n",
    "        if 'range_hl' in df.columns and 'atr_5' in df.columns: # Calculated in XIII\n",
    "            df['range_today'] = df['range_hl'] # Alias for clarity\n",
    "            df['range_atr_5'] = safe_division(df['range_today'], df['atr_5'])\n",
    "            df['range_jump_potential'] = (df['range_atr_5'] > 1.5).astype(int)\n",
    "\n",
    "        # Gap and Go flag\n",
    "        if 'open' in df.columns and 'pre_close' in df.columns:\n",
    "            df['gap_and_go_flag'] = ((safe_division(df['open'], df['pre_close']) - 1 > 0.02) & (df['close'] > df['open'])).astype(int) # Using 2% threshold from snippet\n",
    "\n",
    "\n",
    "    # === XV. 跌不动因子（转债） ===\n",
    "    print(\"计算: XV. 跌不动因子（转债）\")\n",
    "    if 'pct_chg' in df.columns:\n",
    "        print(\"  - 计算下跌频率/幅度/评分...\")\n",
    "        for win in [5, 10]: # Windows from original code\n",
    "            # Down frequency\n",
    "            df[f'down_freq_{win}'] = df.groupby('code')['pct_chg'].transform(\n",
    "                lambda x: x.rolling(win, min_periods=int(win*0.6)).apply(lambda s: (s < 0).mean(), raw=True)\n",
    "            )\n",
    "            # Down amplitude (mean of negative returns)\n",
    "            df[f'down_amp_{win}'] = df.groupby('code')['pct_chg'].transform(\n",
    "                lambda x: x.rolling(win, min_periods=int(win*0.6)).apply(lambda s: s[s < 0].mean() if (s < 0).any() else 0, raw=True)\n",
    "            )\n",
    "            # Score\n",
    "            df[f'no_fall_score_{win}'] = (1 - df[f'down_freq_{win}']) * (-df[f'down_amp_{win}'])\n",
    "\n",
    "\n",
    "    # === XVI. K线结构连续性 ===\n",
    "    print(\"计算: XVI. K线结构连续性\")\n",
    "    if all(c in df.columns for c in ['close', 'open']):\n",
    "        print(\"  - 计算K线方向反转率...\")\n",
    "        df['kline_direction'] = np.sign(df['close'] - df['open'])\n",
    "        df['kline_direction_shift1'] = df.groupby('code')['kline_direction'].shift(1)\n",
    "        if 'kline_direction_shift1' in df.columns: # Check dependency\n",
    "            df['kline_flip'] = (df['kline_direction'] * df['kline_direction_shift1'] < 0).astype(int)\n",
    "            df['kline_flip_ratio_5'] = df.groupby('code')['kline_flip'].transform(lambda x: x.rolling(5, min_periods=3).mean())\n",
    "\n",
    "\n",
    "    # --- Final Cleanup & Optional Index Restore ---\n",
    "    print(\"步骤 XVII: 清理临时列和恢复索引 (如果需要)...\")\n",
    "    # Drop intermediate columns used only for calculation (if any)\n",
    "    cols_to_drop = [\n",
    "        'rank_delta_close_10', 'rank_vol', 'rank_mean_close_20', 'rank_close',\n",
    "        'rank_delta_close_10_stk', 'rank_vol_stk', 'rank_mean_close_20_stk', 'rank_close_stk',\n",
    "        'corr_close_vol_10', 'corr_close_vol_10_stk',\n",
    "        'cov_rank_close_vol_5', 'cov_rank_close_vol_5_stk',\n",
    "        'argmin_close_30_idx_pos', 'argmin_close_30_idx_pos_stk',\n",
    "        # Add other intermediate columns if created e.g. '_high_jump_flag_temp' if used\n",
    "    ]\n",
    "    # Check if columns exist before dropping\n",
    "    cols_exist = [col for col in cols_to_drop if col in df.columns]\n",
    "    if cols_exist:\n",
    "         df = df.drop(columns=cols_exist)\n",
    "\n",
    "    if restore_multiindex and is_multiindex_input:\n",
    "        print(\"  - 恢复 MultiIndex ['code', 'trade_date']...\")\n",
    "        df = df.set_index(['code', 'trade_date'])\n",
    "    elif restore_multiindex and not is_multiindex_input:\n",
    "        print(\"  - 警告: 原始输入没有 MultiIndex，无法恢复。\")\n",
    "\n",
    "\n",
    "    print(\"因子计算完成。\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions (from previous code, ensure they are defined) ---\n",
    "def safe_division(numerator, denominator, default=np.nan):\n",
    "    \"\"\"Performs division, returning default value if denominator is zero, NaN, or invalid.\"\"\"\n",
    "    try:\n",
    "        if hasattr(numerator, '__iter__'): numerator = pd.to_numeric(numerator, errors='coerce')\n",
    "        if hasattr(denominator, '__iter__'):\n",
    "            denominator = pd.to_numeric(denominator, errors='coerce')\n",
    "            denominator = denominator.replace(0, np.nan)\n",
    "        elif isinstance(denominator, (int, float)) and denominator == 0:\n",
    "            denominator = np.nan\n",
    "\n",
    "        result = numerator / denominator\n",
    "\n",
    "        if hasattr(result, '__iter__'):\n",
    "            result = result.replace([np.inf, -np.inf], np.nan)\n",
    "            return result.fillna(default)\n",
    "        elif np.isinf(result) or np.isnan(result):\n",
    "            return default\n",
    "        else:\n",
    "            return result\n",
    "    except (TypeError, ValueError):\n",
    "        shape = getattr(numerator, 'shape', getattr(denominator, 'shape', None))\n",
    "        index = getattr(numerator, 'index', getattr(denominator, 'index', None))\n",
    "        if shape is not None:\n",
    "            return pd.Series(default, index=index, dtype=float)\n",
    "        else:\n",
    "            return default\n",
    "\n",
    "def apply_ta_func(func, group, required_cols, **kwargs):\n",
    "    \"\"\"Safely applies a TA-Lib function to a group.\"\"\"\n",
    "    if group[required_cols].isnull().all().all() or len(group) < kwargs.get('timeperiod', 1)*1.5: # Basic check\n",
    "        return pd.Series(np.nan, index=group.index)\n",
    "    try:\n",
    "        # Prepare arguments for TA-Lib function\n",
    "        args = {col: group[col].astype(float) for col in required_cols}\n",
    "        return func(**args, **kwargs)\n",
    "    except Exception as e:\n",
    "        # print(f\"Error applying {func.__name__} to group: {e}\") # Optional: for debugging\n",
    "        return pd.Series(np.nan, index=group.index)\n",
    "\n",
    "# --- New Advanced Factor Calculation Function ---\n",
    "\n",
    "def apply_ta_func(group, func, required_cols, **kwargs): # group FIRST, then func, required_cols, **kwargs\n",
    "    \"\"\"Safely applies a TA-Lib function to a group.\"\"\"\n",
    "    min_len_needed = 1\n",
    "    if 'timeperiod' in kwargs:\n",
    "        min_len_needed = kwargs['timeperiod']\n",
    "    # Add extra buffer, e.g., 1.5 times the timeperiod, minimum 5 periods for robustness\n",
    "    min_len_needed = max(5, int(min_len_needed * 1.5))\n",
    "\n",
    "    # Check for sufficient non-null data points in required columns\n",
    "    sufficient_data = True\n",
    "    if len(group) < min_len_needed:\n",
    "        sufficient_data = False\n",
    "    else:\n",
    "        # Ensure enough *non-null* values exist in the rolling window equivalent\n",
    "        # This is a proxy check; the actual rolling window might have NaNs internally\n",
    "        non_null_counts = group[required_cols].iloc[-min_len_needed:].notnull().sum()\n",
    "        if any(count < kwargs.get('timeperiod', 1) for count in non_null_counts): # Check if any col has < timeperiod non-nulls\n",
    "             sufficient_data = False\n",
    "\n",
    "    # Handle cases with insufficient or all-NaN data\n",
    "    if not sufficient_data or group[required_cols].isnull().all().all():\n",
    "        return pd.Series(np.nan, index=group.index, dtype=float)\n",
    "\n",
    "    try:\n",
    "        # Prepare arguments for TA-Lib function - ensure they are float arrays\n",
    "        # TA-Lib functions generally expect numpy arrays of float64\n",
    "        args = {col: group[col].astype(float).to_numpy() for col in required_cols}\n",
    "\n",
    "        # Call the TA-Lib function using keyword arguments\n",
    "        result_array = func(**args, **kwargs)\n",
    "\n",
    "        # Return as a pandas Series aligned with the group's index\n",
    "        return pd.Series(result_array, index=group.index, dtype=float)\n",
    "\n",
    "    except Exception as e:\n",
    "        # print(f\"Error applying {func.__name__} to group {group.name if hasattr(group, 'name') else 'N/A'}: {e}\") # Debugging\n",
    "        return pd.Series(np.nan, index=group.index, dtype=float)\n",
    "\n",
    "def calculate_advanced_factors(df, restore_multiindex=False):\n",
    "    \"\"\"\n",
    "    计算补充的高级可转债轮动因子，假设基础因子已通过 calculate_factors 计算。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 包含基础因子的 DataFrame (由 calculate_factors 输出)。\n",
    "        restore_multiindex (bool): 若为True, 在末尾将 ['code', 'trade_date'] 设回索引.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: 添加了高级因子列的DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"开始计算高级因子...\")\n",
    "\n",
    "    required_base_cols = ['code', 'trade_date', 'close', 'high', 'low', 'open', 'pct_chg'] # Minimum required\n",
    "    if not all(col in df.columns or col in df.index.names for col in required_base_cols):\n",
    "         raise ValueError(f\"输入 DataFrame 缺少必要的基础列: {required_base_cols}\")\n",
    "\n",
    "    # --- 索引处理 (与 calculate_factors 类似) ---\n",
    "    original_index = df.index\n",
    "    if isinstance(df.index, pd.MultiIndex) and all(name in df.index.names for name in ['code', 'trade_date']):\n",
    "        print(\"检测到 MultiIndex，正在重置...\")\n",
    "        df = df.reset_index()\n",
    "        is_multiindex_input = True\n",
    "    elif all(col in df.columns for col in ['code', 'trade_date']):\n",
    "        print(\"检测到列 'code', 'trade_date'。\")\n",
    "        is_multiindex_input = False\n",
    "    else: # Should not happen if input comes from calculate_factors\n",
    "        raise ValueError(\"输入 DataFrame 必须包含 'code' 和 'trade_date' 列或索引。\")\n",
    "\n",
    "    # 确保排序 (非常重要)\n",
    "    if not df.index.is_monotonic_increasing or not df.index.is_unique: # Check if previous sort might be disturbed\n",
    "       df = df.sort_values(by=['code', 'trade_date']).copy()\n",
    "    else:\n",
    "       df = df.copy() # Still make a copy to avoid SettingWithCopyWarning\n",
    "    # --- 结束索引处理 ---\n",
    "\n",
    "\n",
    "    # === XVI.b 移动平均线系统 (MA & EMA) 及其偏离度 ===\n",
    "    print(\"计算: XVI.b 移动平均线系统 (MA & EMA) 及其偏离度\")\n",
    "    ma_windows = [5, 10, 20, 30, 50, 60, 120, 250, 500]\n",
    "    if 'close' in df.columns:\n",
    "        print(\"  - 计算转债 MA/EMA 及偏离...\")\n",
    "        for n in ma_windows:\n",
    "            # SMA\n",
    "            df[f'ma_{n}'] = df.groupby('code')['close'].transform(lambda x: ta.SMA(x.astype(float), timeperiod=n))\n",
    "            df[f'ma_dev_{n}'] = safe_division(df['close'], df[f'ma_{n}']) - 1\n",
    "            # EMA\n",
    "            df[f'ema_{n}'] = df.groupby('code')['close'].transform(lambda x: ta.EMA(x.astype(float), timeperiod=n))\n",
    "            df[f'ema_dev_{n}'] = safe_division(df['close'], df[f'ema_{n}']) - 1\n",
    "\n",
    "    if 'close_stk' in df.columns:\n",
    "        print(\"  - 计算股票 MA/EMA 及偏离...\")\n",
    "        for n in ma_windows:\n",
    "            # SMA Stk\n",
    "            df[f'ma_{n}_stk'] = df.groupby('code')['close_stk'].transform(lambda x: ta.SMA(x.astype(float), timeperiod=n))\n",
    "            df[f'ma_dev_{n}_stk'] = safe_division(df['close_stk'], df[f'ma_{n}_stk']) - 1\n",
    "            # EMA Stk\n",
    "            df[f'ema_{n}_stk'] = df.groupby('code')['close_stk'].transform(lambda x: ta.EMA(x.astype(float), timeperiod=n))\n",
    "            df[f'ema_dev_{n}_stk'] = safe_division(df['close_stk'], df[f'ema_{n}_stk']) - 1\n",
    "\n",
    "\n",
    "    # === XVII. 增强型股债背离因子 ===\n",
    "    print(\"计算: XVII. 增强型股债背离因子\")\n",
    "    # 前提: calculate_factors 已计算 stk_ret_mean_X, bond_ret_mean_X, dev_bond_vs_stk_X\n",
    "    required_divergence_cols = ['stk_ret_mean_1', 'stk_ret_mean_3', 'bond_ret_mean_1', 'bond_ret_mean_3', 'dev_bond_vs_stk_1', 'dev_bond_vs_stk_3']\n",
    "    if all(c in df.columns for c in required_divergence_cols):\n",
    "        print(\"  - 计算股强债弱/债超跌/债抗跌 信号...\")\n",
    "        # 股强债弱信号 (示例)\n",
    "        stk_trend_up = (df['stk_ret_mean_3'] > 0.015) & df.get('ma_5_stk', df['close_stk']) > df.get('ma_10_stk', df['close_stk'].shift(5)) # 使用 get 兼容缺失 MA\n",
    "        bond_lagging = (df['bond_ret_mean_3'] < 0.005) & (df['dev_bond_vs_stk_3'] < -0.01)\n",
    "        df['stk_strong_bond_lag_signal'] = (stk_trend_up & bond_lagging).astype(int)\n",
    "\n",
    "        # 债超跌信号\n",
    "        df['bond_oversold_vs_stk_signal'] = ((df['stk_ret_mean_1'] >= -0.01) & (df['bond_ret_mean_1'] < -0.015) & (df['dev_bond_vs_stk_1'] < -0.01)).astype(int) # 调整阈值\n",
    "\n",
    "        # 债抗跌信号\n",
    "        df['bond_resilient_signal'] = ((df['stk_ret_mean_1'] < -0.01) & (df['bond_ret_mean_1'] > -0.005) & (df['dev_bond_vs_stk_1'] > 0.005)).astype(int)\n",
    "\n",
    "        print(\"  - 计算股债背离 Z-Score...\")\n",
    "        # 股债收益差 Z-Score\n",
    "        dev_mean = df.groupby('code')['dev_bond_vs_stk_3'].transform(lambda x: x.rolling(20, min_periods=10).mean())\n",
    "        dev_std = df.groupby('code')['dev_bond_vs_stk_3'].transform(lambda x: x.rolling(20, min_periods=10).std())\n",
    "        df['dev_bond_vs_stk_zscore_3'] = safe_division(df['dev_bond_vs_stk_3'] - dev_mean, dev_std)\n",
    "    else:\n",
    "        print(\"  警告: 缺少计算增强背离因子所需的基础因子。\")\n",
    "\n",
    "\n",
    "    # === XVIII. 动量加速与趋势持续性因子 ===\n",
    "    print(\"计算: XVIII. 动量加速与趋势持续性因子\")\n",
    "    if all(c in df.columns for c in ['bond_ret_mean_1', 'bond_ret_mean_3']):\n",
    "        print(\"  - 计算转债动量加速...\")\n",
    "        df['bond_ret_accel_1_3'] = df['bond_ret_mean_1'] - df.groupby('code')['bond_ret_mean_3'].shift(1)\n",
    "    if all(c in df.columns for c in ['stk_ret_mean_1', 'stk_ret_mean_3']):\n",
    "        print(\"  - 计算股票动量加速...\")\n",
    "        df['stk_ret_accel_1_3'] = df['stk_ret_mean_1'] - df.groupby('code')['stk_ret_mean_3'].shift(1)\n",
    "\n",
    "    # # ADX / CCI\n",
    "    # ta_adx_cci_cols = ['high', 'low', 'close']\n",
    "    # if all(c in df.columns for c in ta_adx_cci_cols):\n",
    "    #     print(\"  - 计算转债 ADX/CCI...\")\n",
    "    #     df['adx_14'] = df.groupby('code', group_keys=False).apply(apply_ta_func, func=ta.ADX, required_cols=ta_adx_cci_cols, timeperiod=14)\n",
    "    #     df['cci_14'] = df.groupby('code', group_keys=False).apply(apply_ta_func, func=ta.CCI, required_cols=ta_adx_cci_cols, timeperiod=14)\n",
    "\n",
    "    # ta_adx_cci_cols_stk = ['high_stk', 'low_stk', 'close_stk']\n",
    "    # if all(c in df.columns for c in ta_adx_cci_cols_stk):\n",
    "    #     print(\"  - 计算股票 ADX/CCI...\")\n",
    "    #     df['adx_14_stk'] = df.groupby('code', group_keys=False).apply(apply_ta_func, func=ta.ADX, required_cols=ta_adx_cci_cols_stk, timeperiod=14)\n",
    "    #     df['cci_14_stk'] = df.groupby('code', group_keys=False).apply(apply_ta_func, func=ta.CCI, required_cols=ta_adx_cci_cols_stk, timeperiod=14)\n",
    "     # ADX / CCI\n",
    "    # ADX / CCI\n",
    "    ta_adx_cci_cols = ['high', 'low', 'close']\n",
    "    if all(c in df.columns for c in ta_adx_cci_cols):\n",
    "        print(\"  - 计算转债 ADX/CCI (using lambda)...\")\n",
    "        # Use lambda to explicitly pass args to the re-defined helper\n",
    "        df['adx_14'] = df.groupby('code', group_keys=False).apply(\n",
    "            lambda group: apply_ta_func(group, func=ta.ADX, required_cols=ta_adx_cci_cols, timeperiod=14)\n",
    "        )\n",
    "        df['cci_14'] = df.groupby('code', group_keys=False).apply(\n",
    "            lambda group: apply_ta_func(group, func=ta.CCI, required_cols=ta_adx_cci_cols, timeperiod=14)\n",
    "        )\n",
    "\n",
    "    ta_adx_cci_cols_stk = ['high_stk', 'low_stk', 'close_stk']\n",
    "    if all(c in df.columns for c in ta_adx_cci_cols_stk):\n",
    "        print(\"  - 计算股票 ADX/CCI (using lambda)...\")\n",
    "        df['adx_14_stk'] = df.groupby('code', group_keys=False).apply(\n",
    "            lambda group: apply_ta_func(group, func=ta.ADX, required_cols=ta_adx_cci_cols_stk, timeperiod=14)\n",
    "        )\n",
    "        df['cci_14_stk'] = df.groupby('code', group_keys=False).apply(\n",
    "            lambda group: apply_ta_func(group, func=ta.CCI, required_cols=ta_adx_cci_cols_stk, timeperiod=14)\n",
    "        )\n",
    "\n",
    "    # === XIX. 脉冲潜力与精确风险评估 ===\n",
    "    print(\"计算: XIX. 脉冲潜力与精确风险评估\")\n",
    "    # 脉冲准备分数 (示例)\n",
    "    print(\"  - 计算脉冲准备分数...\")\n",
    "    # 使用 .get() 以防基础因子缺失\n",
    "    df['pulse_readiness_score'] = (df.get('vol_shrink_ratio', 1) + # 越小越好\n",
    "                                 df.get('vol_std_decay', 1) +    # 越小越好\n",
    "                                 df.get('doji_ratio_5', 1) +     # 越多可能震荡末端\n",
    "                                 df.get('body_pct_mean_5', 1) * 5 # 实体越小越好，放大权重\n",
    "                                 ).rank(pct=True) # 直接转换为百分位排名，值越小越好\n",
    "\n",
    "    # 上下行波动率对比\n",
    "    print(\"  - 计算上下行波动率对比...\")\n",
    "    if 'pct_chg' in df.columns:\n",
    "        def calc_up_down_vol(group, window=20): # Use longer window\n",
    "            series = group['pct_chg']\n",
    "            up_vol = series.where(series > 0).rolling(window, min_periods=max(2, int(window*0.5))).std().fillna(0)\n",
    "            down_vol = series.where(series < 0).rolling(window, min_periods=max(2, int(window*0.5))).std().fillna(0)\n",
    "            return pd.DataFrame({'upside_vol_20': up_vol, 'downside_vol_20': down_vol}, index=group.index)\n",
    "\n",
    "        vol_df = df.groupby('code', group_keys=False).apply(calc_up_down_vol)\n",
    "        df = df.join(vol_df)\n",
    "        df['upside_bias_vol_20'] = safe_division(df.get('upside_vol_20'), df.get('downside_vol_20'))\n",
    "\n",
    "    # 近期脉冲成功率\n",
    "    print(\"  - 计算近期脉冲成功率...\")\n",
    "    if all(c in df.columns for c in ['high', 'open', 'close']):\n",
    "        df['intra_pulse_15'] = (safe_division(df['high'], df['open']) - 1) > 0.015 # 日内脉冲 > 1.5%\n",
    "        df['pulse_success_15'] = df['intra_pulse_15'] & (df['close'] > df['open']) # 脉冲且收阳\n",
    "        df['recent_pulse_success_rate_20'] = df.groupby('code')['pulse_success_15'].transform(lambda x: x.rolling(20, min_periods=10).mean())\n",
    "\n",
    "    # 历史风险回报比\n",
    "    print(\"  - 计算历史风险回报比...\")\n",
    "    if 'pct_chg' in df.columns:\n",
    "        mean_up = df.groupby('code')['pct_chg'].transform(lambda x: x[x > 0].rolling(60, min_periods=20).mean())\n",
    "        mean_down_abs = df.groupby('code')['pct_chg'].transform(lambda x: x[x < 0].abs().rolling(60, min_periods=20).mean())\n",
    "        df['risk_reward_ratio_hist_60'] = safe_division(mean_up, mean_down_abs)\n",
    "\n",
    "\n",
    "    # === XX. 市场情绪与相对强度因子 ===\n",
    "    print(\"计算: XX. 市场情绪与相对强度因子\")\n",
    "    # Beta (需要指数数据，此处注释掉)\n",
    "    # if 'index_ret' in df.columns and 'pct_chg' in df.columns:\n",
    "    #     print(\"  - 计算滚动 Beta...\")\n",
    "    #     cov = df.groupby('code').apply(lambda x: x['pct_chg'].rolling(20, min_periods=12).cov(x['index_ret'])).reset_index(level=0, drop=True)\n",
    "    #     var_index = df.groupby('code')['index_ret'].transform(lambda x: x.rolling(20, min_periods=12).var())\n",
    "    #     df['beta_rolling_20'] = safe_division(cov, var_index)\n",
    "    # else:\n",
    "    #     print(\"  - 跳过 Beta 计算 (缺少 'index_ret' 列)。\")\n",
    "\n",
    "    # 行业相对强度 (需要行业数据，此处注释掉)\n",
    "    # if 'sector_ret' in df.columns and 'pct_chg_stk' in df.columns:\n",
    "    #     print(\"  - 计算行业相对强度...\")\n",
    "    #     df['relative_strength_sector'] = df['pct_chg_stk'] - df['sector_ret']\n",
    "    # else:\n",
    "    #     print(\"  - 跳过行业相对强度计算 (缺少 'sector_ret' 列)。\")\n",
    "\n",
    "    # 关键因子截面排名\n",
    "    print(\"  - 计算关键因子截面排名...\")\n",
    "    factors_to_rank = {\n",
    "        'dev_bond_vs_stk_3': True,         # 背离越大越差? (False) or 越小越好 (True)? 假设 True: 小 (滞涨) 好\n",
    "        'stk_strong_bond_lag_signal': False, # 信号=1 好\n",
    "        'pulse_readiness_score': True,     # 分数越小越好\n",
    "        # 'down_freq_20': True,            # 假设 calculate_factors 已计算, 频率越小越好\n",
    "        'risk_reward_ratio_hist_60': False,# 比率越大越好\n",
    "        'upside_bias_vol_20': False,       # 比率越大越好\n",
    "    }\n",
    "    for factor, ascending in factors_to_rank.items():\n",
    "        if factor in df.columns:\n",
    "            df[f'rank_{factor}'] = df.groupby('trade_date')[factor].rank(method='first', ascending=ascending, pct=True) # 使用百分位排名\n",
    "        else:\n",
    "            print(f\"  警告: 因子 '{factor}' 不存在，无法计算排名。\")\n",
    "\n",
    "    # --- Final Cleanup & Optional Index Restore ---\n",
    "    print(\"步骤 XXI: 清理和恢复索引 (如果需要)...\")\n",
    "\n",
    "    if restore_multiindex and is_multiindex_input:\n",
    "        print(\"  - 恢复 MultiIndex ['code', 'trade_date']...\")\n",
    "        df = df.set_index(['code', 'trade_date'])\n",
    "        # 确保索引仍然排序\n",
    "        if not df.index.is_monotonic_increasing:\n",
    "             df = df.sort_index()\n",
    "    elif restore_multiindex and not is_multiindex_input:\n",
    "        print(\"  - 警告: 原始输入没有 MultiIndex，无法恢复。\")\n",
    "\n",
    "\n",
    "    print(\"高级因子计算完成。\")\n",
    "    return df\n",
    "\n",
    "# --- Example Usage ---\n",
    "# 1. 首先运行基础因子计算\n",
    "# df_base_factors = calculate_factors(df_raw.copy(), restore_multiindex=False) # Ensure output has columns\n",
    "\n",
    "# 2. 然后运行高级因子计算\n",
    "# df_advanced_factors = calculate_advanced_factors(df_base_factors.copy(), restore_multiindex=True) # Can restore index at the end\n",
    "\n",
    "# print(df_advanced_factors.info())\n",
    "# print(df_advanced_factors.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始因子计算...\n",
      "检测到 'code' 和 'trade_date' 在 MultiIndex 中，正在重置索引...\n",
      "步骤 0: 准备数据类型...\n",
      "计算: I. 基本价格与波动类因子（转债本身）\n",
      "  - 计算 NATR...\n",
      "  - 计算 MA, Momentum, Volatility...\n",
      "  - 计算次日止盈特征...\n",
      "计算: II. OBV量能指标（转债）\n",
      "计算: III. 换手与市值类因子\n",
      "  - 计算 turnover 相关因子...\n",
      "  - 计算 cap_float_share_rate...\n",
      "计算: IV. 区间收益率（转债与股票）\n",
      "  - 计算转债区间收益率...\n",
      "  - 计算股票区间收益率...\n",
      "计算: V. 成交量均值比因子（转债）\n",
      "  - 计算均量...\n",
      "  - 计算量比...\n",
      "计算: VI. 波动率与振幅（转债与股票）\n",
      "  - 计算股票波动率...\n",
      "  - 计算转债波动率...\n",
      "  - 计算振幅波动...\n",
      "计算: VII. 跳空与缺口类因子（转债）\n",
      "  - 计算基础跳空/缺口指标...\n",
      "  - 计算跳空/缺口统计...\n",
      "计算: VIII. K线结构因子（转债）\n",
      "计算: IX. 趋势反转类Alpha因子（转债与股票）\n",
      "  - 计算 Alpha 因子前置数据...\n",
      "  - 计算截面排名 (可能较慢)...\n",
      "  - 计算 Alpha6...\n",
      "  - 计算 Alpha12...\n",
      "  - 计算 Alpha83...\n",
      "  - 计算 Alpha18...\n",
      "  - 计算 Alpha36...\n",
      "  - 计算 Alpha89...\n",
      "  - 计算 Alpha65...\n",
      "  - 计算 Alpha76...\n",
      "  - 计算 Alpha92...\n",
      "  - 计算 Alpha99...\n",
      "计算: X. 股票与转债联动因子\n",
      "  - 计算日内联动...\n",
      "  - 计算多日联动 (滞涨)...\n",
      "计算: XI. 横纵向背离因子（股票与转债）\n",
      "  - 计算横向背离...\n",
      "  - 计算纵向背离...\n",
      "计算: XII. 风险与回撤相关因子（转债）\n",
      "  - 计算低点距离/标准差/回撤...\n",
      "  - 计算下跌风险预估...\n",
      "计算: XIII. 震荡收敛类因子（转债）\n",
      "  - 计算 ATR/振幅/价格波动 收敛...\n",
      "  - 计算 K线实体/影线/十字星 特征...\n",
      "计算: XIV. 脉冲与动能因子（转债）\n",
      "  - 计算高脉冲统计 (count, mean, score)...\n",
      "  - 计算其他脉冲指标...\n",
      "计算: XV. 跌不动因子（转债）\n",
      "  - 计算下跌频率/幅度/评分...\n",
      "计算: XVI. K线结构连续性\n",
      "  - 计算K线方向反转率...\n",
      "步骤 XVII: 清理临时列和恢复索引 (如果需要)...\n",
      "因子计算完成。\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # 当列太多时不换行\n",
    "df = pd.read_parquet('/Users/yiwei/Desktop/git/cb_data.pq') # 导入转债数据\n",
    "# index = pd.read_parquet('/Users/yiwei/Desktop/git/index.pq') # 导入指数数据\n",
    "\n",
    "# df_all = load_and_prepare_data('/Users/yiwei/Desktop/git/cb_data.pq')\n",
    "\n",
    "df_with_factors = calculate_factors(df)\n",
    "\n",
    "\n",
    "df_with_factors.to_parquet('/Users/yiwei/Desktop/git/cb_data_with_factors2.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始计算高级因子...\n",
      "检测到列 'code', 'trade_date'。\n",
      "计算: XVI.b 移动平均线系统 (MA & EMA) 及其偏离度\n",
      "  - 计算转债 MA/EMA 及偏离...\n",
      "  - 计算股票 MA/EMA 及偏离...\n",
      "计算: XVII. 增强型股债背离因子\n",
      "  警告: 缺少计算增强背离因子所需的基础因子。\n",
      "计算: XVIII. 动量加速与趋势持续性因子\n",
      "  - 计算转债 ADX/CCI (using lambda)...\n",
      "  - 计算股票 ADX/CCI (using lambda)...\n",
      "计算: XIX. 脉冲潜力与精确风险评估\n",
      "  - 计算脉冲准备分数...\n",
      "  - 计算上下行波动率对比...\n",
      "  - 计算近期脉冲成功率...\n",
      "  - 计算历史风险回报比...\n",
      "计算: XX. 市场情绪与相对强度因子\n",
      "  - 计算关键因子截面排名...\n",
      "  警告: 因子 'stk_strong_bond_lag_signal' 不存在，无法计算排名。\n",
      "步骤 XXI: 清理和恢复索引 (如果需要)...\n",
      "高级因子计算完成。\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)  # 当列太多时不换行\n",
    "df = pd.read_parquet('/Users/yiwei/Desktop/git/cb_data_with_factors2.pq') # 导入转债数据\n",
    "\n",
    "cb_data_with_factors_enhanced = calculate_advanced_factors(df)\n",
    "\n",
    "cb_data_with_factors_enhanced.to_parquet('/Users/yiwei/Desktop/git/cb_data_with_factors_enhanced.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新增部分：涨不动 + 跌不动 + 脉冲可能性因子组合（含组合筛选示例）\n",
    "# =========================\n",
    "\n",
    "# ...（原有因子保留，此处省略）...\n",
    "\n",
    "# =========================\n",
    "# DEMO：组合 signal 示例（筛选后重新排名）\n",
    "# =========================\n",
    "\n",
    "# 目标：选出“跌不动 + 收敛”中的个股，再对其在 turnover 和脉冲潜力上重新打分\n",
    "\n",
    "# 1️⃣ 筛选条件（如：跌不动 + 收敛）\n",
    "filter_mask = (df['no_fall_score_10'] > 0.01) & (df['atr_decay_5_10'] < 0.8)\n",
    "df_filtered = df[filter_mask].copy()\n",
    "\n",
    "# 2️⃣ 在子集内重新横截面排名（打分因子：turnover + 脉冲潜力）\n",
    "df_filtered['turnover_score'] = df_filtered.groupby('trade_date')['turnover'].rank(pct=True)\n",
    "df_filtered['surge_score'] = df_filtered.groupby('trade_date')['jump_atr_5'].rank(pct=True)\n",
    "\n",
    "# 3️⃣ 综合打分\n",
    "# 权重可以调整，这里默认 0.5 + 0.5\n",
    "df_filtered['combo_score'] = 0.5 * df_filtered['turnover_score'] + 0.5 * df_filtered['surge_score']\n",
    "\n",
    "# 4️⃣ 输出最终 signal（如：得分 > 80%）\n",
    "df_filtered['signal_combo_top20'] = (df_filtered.groupby('trade_date')['combo_score'].rank(pct=True) > 0.8).astype(int)\n",
    "\n",
    "# 5️⃣ 可选：将信号回填回主 df（非必须）\n",
    "df = df.merge(df_filtered[['code', 'trade_date', 'signal_combo_top20']], on=['code', 'trade_date'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt v1:\n",
    "# 可转债 + 正股 因子计算模块（剔除打分/排名逻辑，按分类顺序整理）\n",
    "# =========================\n",
    "\n",
    "# === 🟡 波动/收敛类因子 ===\n",
    "df['atr_5'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "df['atr_20'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(20).mean()).reset_index(0, drop=True)\n",
    "df['atr_5_decay'] = df['atr_5'] / df['atr_20']\n",
    "\n",
    "# 振幅收敛\n",
    "df['zhengfu_5'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "df['zhengfu_20'] = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(20).mean()).reset_index(0, drop=True)\n",
    "df['zhengfu_decay_5_20'] = df['zhengfu_5'] / df['zhengfu_20']\n",
    "range_5 = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(5).mean()).reset_index(0, drop=True)\n",
    "range_20 = df.groupby('code').apply(lambda x: (x['high'] - x['low']).rolling(20).mean()).reset_index(0, drop=True)\n",
    "df['range_ratio_5_20'] = range_5 / range_20\n",
    "\n",
    "# K线结构收敛\n",
    "df['body'] = (df['close'] - df['open']).abs()\n",
    "df['shadow'] = (df['high'] - df['low']) - df['body']\n",
    "df['small_body_shadow_ratio'] = df['shadow'] / (df['body'] + 1e-6)\n",
    "df['is_doji'] = (df['body'] / (df['high'] - df['low'] + 1e-6)) < 0.15\n",
    "df['doji_ratio_5'] = df.groupby('code')['is_doji'].rolling(5).mean().reset_index(0, drop=True)\n",
    "\n",
    "# === ⚡️ 脉冲类因子 ===\n",
    "for thres in [0.015, 0.02, 0.03, 0.04, 0.05, 0.06]:\n",
    "    df[f'high_jump_{int(thres*1000)}'] = ((df['high'] / df['pre_close'] - 1) > thres).astype(int)\n",
    "\n",
    "for n in [3, 5, 10]:\n",
    "    high_mean = df.groupby('code')['high'].rolling(n).mean().reset_index(0, drop=True)\n",
    "    close_mean = df.groupby('code')['close'].rolling(n).mean().reset_index(0, drop=True)\n",
    "    close_std = df.groupby('code')['close'].rolling(n).std().reset_index(0, drop=True)\n",
    "    df[f'jump_atr_{n}'] = (df['high'] - close_mean) / (close_std + 1e-6)\n",
    "\n",
    "df['zscore_pctchg_20'] = df.groupby('code')['pct_chg'].transform(lambda x: (x - x.rolling(20).mean()) / (x.rolling(20).std() + 1e-6))\n",
    "df['range_today'] = df['high'] - df['low']\n",
    "df['range_atr_5'] = df['range_today'] / df.groupby('code')['range_today'].rolling(5).mean().reset_index(0, drop=True)\n",
    "df['range_jump_potential'] = (df['range_atr_5'] > 1.5).astype(int)\n",
    "\n",
    "# === 📉 跌不动类因子 ===\n",
    "for win in [5, 10]:\n",
    "    df[f'down_freq_{win}'] = df.groupby('code')['pct_chg'].apply(lambda x: x.rolling(win).apply(lambda s: (s < 0).mean())).reset_index(0, drop=True)\n",
    "    df[f'down_amp_{win}'] = df.groupby('code')['pct_chg'].apply(lambda x: x.rolling(win).apply(lambda s: s[s < 0].mean() if (s < 0).any() else 0)).reset_index(0, drop=True)\n",
    "    df[f'no_fall_score_{win}'] = (1 - df[f'down_freq_{win}']) * (-df[f'down_amp_{win}'])\n",
    "\n",
    "# === 🔁 情绪与结构类因子 ===\n",
    "vol_ma20 = df.groupby('code')['volume'].rolling(20).mean().reset_index(0, drop=True)\n",
    "df['vol_spike_ratio'] = df['volume'] / (vol_ma20 + 1e-6)\n",
    "vol_std_5 = df.groupby('code')['volume'].rolling(5).std().reset_index(0, drop=True)\n",
    "vol_std_20 = df.groupby('code')['volume'].rolling(20).std().reset_index(0, drop=True)\n",
    "df['vol_std_decay'] = vol_std_5 / (vol_std_20 + 1e-6)\n",
    "df['gap_and_go_flag'] = ((df['open'] > df['pre_close'] * 1.02) & (df['close'] > df['open'])).astype(int)\n",
    "df['gap_body_ratio'] = (df['open'] - df['pre_close']) / (df['close'] - df['open']).replace(0, np.nan)\n",
    "\n",
    "# === 📈 正股版本（带 _stk）可选镜像字段 ===\n",
    "# 注：下方是正股与转债因子镜像，便于后续联动对比分析\n",
    "df['jump_atr_5_stk'] = (df['high_stk'] - df.groupby('code')['close_stk'].rolling(5).mean().reset_index(0, drop=True)) / \\\n",
    "                        (df.groupby('code')['close_stk'].rolling(5).std().reset_index(0, drop=True) + 1e-6)\n",
    "df['vol_spike_ratio_stk'] = df['vol_stk'] / (df.groupby('code')['vol_stk'].rolling(20).mean().reset_index(0, drop=True) + 1e-6)\n",
    "df['gap_and_go_flag_stk'] = ((df['open_stk'] > df['pre_close_stk'] * 1.02) & (df['close_stk'] > df['open_stk'])).astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
